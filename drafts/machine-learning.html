<!doctype html>
<html class="no-js" lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />

		<title>kamidox.com</title>
		<meta name="description" content="">
		<meta name="author" content="Joey Huang">

		<link rel="stylesheet" href="../theme/css/foundation.css" />
		<link rel="stylesheet" href="../theme/css/pygment/monokai.css" />
		<link rel="stylesheet" href="../theme/css/custom.css" />


		<link rel="shortcut icon" href="../theme/img/favicon.ico">

		<script src="../theme/js/modernizr.js"></script>

		<!-- Feeds -->


		<!-- mathjax config similar to math.stackexchange -->
		<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
		<script>
		MathJax.Hub.Config({
		  config: ["MMLorHTML.js"],
		  extensions: ["tex2jax.js"],
		  jax: ["input/TeX"],
		  tex2jax: {
		    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
		    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
		    processEscapes: false
		  },
		  TeX: {
		    extensions: ["AMSmath.js", "AMSsymbols.js"],
		    TagSide: "right",
		    TagIndent: ".8em",
		    MultLineWidth: "85%",
		    equationNumbers: {
		      autoNumber: "AMS",
		    },
		    unicode: {
		      fonts: "STIXGeneral,'Arial Unicode MS'"
		    }
		  },
		  showProcessingMessages: false
		});
		</script>
	</head>
	<body>
		<div class="off-canvas-wrap">
			<div class="inner-wrap">
				<!-- mobile top bar to activate nav -->
				<nav class="tab-bar show-for-small">
					<section class="left-small">
						<a class="left-off-canvas-toggle menu-icon" ><span></span></a>
					</section>

					<section class="middle tab-bar-section">
						<h1 class="title">kamidox.com</h1>
					</section>
				</nav>

				<!-- mobile side bar nav -->
				<aside class="left-off-canvas-menu">
					<ul class="off-canvas-list">
							<li><a href="http://blog.kamidox.com">Home</a></li>
							<li><a href="about.html">About</a></li>

						<li><label>Categories</label></li>
							<li ><a href="../category/android.html">android</a></li>
							<li ><a href="../category/essay.html">essay</a></li>
							<li ><a href="../category/flask.html">flask</a></li>
							<li ><a href="../category/ml.html">ml</a></li>
							<li ><a href="../category/python.html">python</a></li>
							<li ><a href="../category/tools.html">tools</a></li>
							<li ><a href="../category/werkzeug.html">werkzeug</a></li>




						<li><label>Monthly Archives</label></li>
									<li><a href="/posts/2016/01/index.html">January 2016 (1)</a></li>
									<li><a href="/posts/2015/12/index.html">December 2015 (10)</a></li>
									<li><a href="/posts/2015/11/index.html">November 2015 (6)</a></li>
									<li><a href="/posts/2015/10/index.html">October 2015 (2)</a></li>
									<li><a href="/posts/2015/09/index.html">September 2015 (7)</a></li>
									<li><a href="/posts/2015/08/index.html">August 2015 (1)</a></li>
									<li><a href="/posts/2015/07/index.html">July 2015 (1)</a></li>
									<li><a href="/posts/2015/05/index.html">May 2015 (1)</a></li>
									<li><a href="/posts/2015/04/index.html">April 2015 (1)</a></li>
									<li><a href="/posts/2015/03/index.html">March 2015 (3)</a></li>
									<li><a href="/posts/2015/02/index.html">February 2015 (2)</a></li>
									<li><a href="/posts/2015/01/index.html">January 2015 (2)</a></li>
									<li><a href="/posts/2014/12/index.html">December 2014 (3)</a></li>
									<li><a href="/posts/2014/11/index.html">November 2014 (4)</a></li>
									<li><a href="/posts/2014/10/index.html">October 2014 (6)</a></li>
									<li><a href="/posts/2014/09/index.html">September 2014 (1)</a></li>
									<li><a href="/posts/2014/07/index.html">July 2014 (1)</a></li>


					</ul>
				</aside>

				<!-- top bar nav -->
				<nav class="top-bar hide-for-small-only" data-topbar>
					<ul class="title-area">
						<li class="name">
							<h1><a href="../">kamidox.com</a></h1>
						</li>
					</ul>

					<section class="top-bar-section">
						<ul class="left">
								<li><a href="http://blog.kamidox.com">Home</a></li>
								<li><a href="about.html">About</a></li>

						</ul>
					</section>
				</nav>

				<!-- Main Page Content and Sidebar -->
				<section class="main-section">
					<div class="row">
						<!-- Main Content -->
						<div class="medium-9 small-12 columns" role="content">
<article>
	<h2>Machine Learning</h2>
	<div class="toc">
<ul>
<li><a href="#_1">机器学习</a></li>
<li><a href="#week-1">Week 1 机器学习介绍</a><ul>
<li><a href="#what-is-machine-learning">What is Machine Learning?</a></li>
<li><a href="#supervised-learning">Supervised learning</a></li>
<li><a href="#unsupervised-learning">Unsupervised learning</a></li>
<li><a href="#_2">线性回归算法</a></li>
<li><a href="#_3">数学</a></li>
<li><a href="#_4">术语</a></li>
<li><a href="#todo">TODO</a></li>
</ul>
</li>
<li><a href="#week-2">Week 2 多变量梯度下降算法</a><ul>
<li><a href="#_5">多变量梯度下降算法</a></li>
<li><a href="#feature-scaling">变量缩放 Feature Scaling</a></li>
<li><a href="#_6">学习率</a></li>
<li><a href="#normal-equalation">标准方程 Normal Equalation</a></li>
<li><a href="#octave">Octave 教程</a><ul>
<li><a href="#octave_1">Octave 基本教程</a></li>
<li><a href="#_7">向量化</a></li>
<li><a href="#_8">标准方程和奇异矩阵</a></li>
</ul>
</li>
<li><a href="#todo_1">TODO</a></li>
</ul>
</li>
<li><a href="#week-3-logistic-regression">Week 3 分类回归算法 Logistic Regression</a><ul>
<li><a href="#classification-and-representation">分类预测函数及其表现形式 Classification and Representation</a><ul>
<li><a href="#_9">引言 为什么需要分类回归算法</a></li>
<li><a href="#hypothesis-representation">逻辑回归预测函数的表现形式 Hypothesis Representation</a></li>
<li><a href="#decision-boundary">判定边界 Decision Boundary</a></li>
</ul>
</li>
<li><a href="#_10">逻辑回归的成本函数</a><ul>
<li><a href="#_11">逻辑回归成本函数定义</a></li>
</ul>
</li>
<li><a href="#_12">算法优化</a></li>
<li><a href="#_13">多元分类算法</a></li>
<li><a href="#regularization">正则化 Regularization</a><ul>
<li><a href="#_14">线性回归里的欠拟合和过拟合</a></li>
<li><a href="#_15">正则化</a></li>
<li><a href="#_16">通用方程的正则化</a></li>
<li><a href="#_17">逻辑回归成本函数的正则化</a></li>
</ul>
</li>
<li><a href="#todo_2">TODO</a></li>
</ul>
</li>
<li><a href="#week-4-neural-networks-presentation">Week 4 神经网络表示 Neural Networks: Presentation</a><ul>
<li><a href="#motivations">动机 Motivations</a></li>
<li><a href="#_18">神经网络模型</a><ul>
<li><a href="#_19">神经元</a></li>
<li><a href="#_20">神经网络</a></li>
<li><a href="#forward-propagation-vectorized-implementation">向前传播算法的向量化实现 Forward Propagation: Vectorized Implementation</a></li>
</ul>
</li>
<li><a href="#_21">神经网络的应用实例</a><ul>
<li><a href="#_22">运用神经网络来模拟逻辑运算</a></li>
<li><a href="#_23">运用神经网络来处理多类别的分类问题</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#week-5-neural-networks-learning">Week 5 神经网络学习 Neural Networks: Learning</a><ul>
<li><a href="#_24">成本函数</a></li>
<li><a href="#_25">向后传播算法</a></li>
<li><a href="#backpropagation-in-practice">实践中的向后传播算法 Backpropagation in Practice</a><ul>
<li><a href="#_26">参数折叠</a></li>
<li><a href="#_27">微分项检验</a></li>
<li><a href="#_28">用随机数初始化参数</a></li>
</ul>
</li>
<li><a href="#_29">总结</a><ul>
<li><a href="#_30">神经网络架构</a></li>
<li><a href="#_31">神经网络训练</a></li>
</ul>
</li>
<li><a href="#todo_3">TODO</a></li>
</ul>
</li>
<li><a href="#week-6">Week 6 机器学习应用的最佳实践以及系统设计</a><ul>
<li><a href="#_32">机器学习算法的性能评估</a><ul>
<li><a href="#_33">为什么需要评估机器学习算法的性能</a></li>
<li><a href="#_34">预测函数模型性能评估</a></li>
<li><a href="#_35">模型选择</a></li>
<li><a href="#bias-vs-variance">方差与偏差 Bias vs. Variance</a></li>
<li><a href="#_36">正则化与方差及偏差的关系</a></li>
<li><a href="#_37">学习曲线</a></li>
<li><a href="#_38">决定下一步行动</a></li>
</ul>
</li>
<li><a href="#_39">机器学习系统设计</a><ul>
<li><a href="#_40">构建垃圾邮件过滤系统</a></li>
<li><a href="#_41">错误分析</a></li>
<li><a href="#_42">处理有倾向性的数据</a></li>
<li><a href="#_43">在查准率和召回率之间权衡</a></li>
<li><a href="#_44">使用大量的数据集</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#week-7-svm-support-vector-machine">Week 7 支持向量机算法 SVM (Support Vector Machine)</a><ul>
<li><a href="#_45">大间距分类算法</a><ul>
<li><a href="#_46">支持向量机算法的成本函数</a></li>
<li><a href="#_47">支持向量机的数学原理</a></li>
</ul>
</li>
<li><a href="#_48">核</a><ul>
<li><a href="#_49">核函数</a></li>
<li><a href="#_50">使用核函数来解决支持向量机算法</a></li>
</ul>
</li>
<li><a href="#svm">实践中的 SVM</a></li>
<li><a href="#todo_4">TODO</a></li>
</ul>
</li>
<li><a href="#week-8-unsupervised-learning">Week 8 无监督式学习 Unsupervised Learning</a><ul>
<li><a href="#clustering">聚类问题 Clustering</a><ul>
<li><a href="#k">K 均值算法</a></li>
<li><a href="#k_1">K 均值算法成本函数</a></li>
<li><a href="#_51">随机初始化聚类中心点</a></li>
<li><a href="#_52">选择聚类的个数</a></li>
</ul>
</li>
<li><a href="#dimensionality-reduction">维数约减 Dimensionality Reduction</a><ul>
<li><a href="#_53">动机</a></li>
<li><a href="#principal-component-analysis-pca">主成份分析法 Principal Component Analysis (PCA)</a></li>
<li><a href="#pca">PCA 应用</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#week-9">Week 9 异常检测和推荐系统</a><ul>
<li><a href="#_54">异常检测</a><ul>
<li><a href="#_55">异常检测模型和实例</a></li>
<li><a href="#_56">高斯分布</a></li>
<li><a href="#_57">异常检测算法</a></li>
<li><a href="#_58">异常检测算法的性能评价</a></li>
<li><a href="#_59">异常检测与监督学习的区别</a></li>
<li><a href="#_60">异常检测中的特征选择</a></li>
<li><a href="#_61">多元高斯分布</a></li>
<li><a href="#_62">使用多元高斯分布进行异常检测</a></li>
</ul>
</li>
<li><a href="#_63">推荐系统</a><ul>
<li><a href="#_64">推荐系统的描述</a></li>
<li><a href="#_65">基于内容的推荐算法</a></li>
<li><a href="#collaborative-filtering">协同过滤算法 Collaborative Filtering</a></li>
<li><a href="#_66">协同过滤算法的实现</a></li>
<li><a href="#_67">协同过滤算法的向量化实现</a></li>
<li><a href="#mean-normalization">均值归一化 Mean Normalization</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#week-10">Week 10 大规模机器学习</a><ul>
<li><a href="#_68">大规模数据的梯度下降算法</a><ul>
<li><a href="#_69">大规模数据的算法学习</a></li>
<li><a href="#stochastic-gradient-descent">随机梯度下降算法 Stochastic gradient descent</a></li>
<li><a href="#_70">小批量梯度下降</a></li>
<li><a href="#_71">检查随机梯度下降算法是否收敛</a></li>
</ul>
</li>
<li><a href="#_72">高级话题</a><ul>
<li><a href="#_73">在线学习</a></li>
<li><a href="#map-reduce-and-data-parallelism">映射化简和数据并行处理 Map Reduce and Data Parallelism</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#week-11-ocr">Week 11 图像 OCR</a><ul>
<li><a href="#_74">问题描述和机器学习流水线</a></li>
<li><a href="#_75">滑动窗口</a></li>
<li><a href="#_76">人工合成数据</a></li>
<li><a href="#ceiling-analysis">上限分析 Ceiling Analysis</a></li>
</ul>
</li>
<li><a href="#_77">课程总结</a></li>
</ul>
</div>
<h2 id="_1">机器学习</h2>
<p>课程在 <a href="https://www.coursera.org/learn/machine-learning/home/welcome">Coursera</a> 上, 讲师是 Andrew Ng。PDF 格式的课件在 <a href="http://cs229.stanford.edu/materials.html">Stanford 网站</a>上。课程讨论组在<a href="https://www.coursera.org/learn/machine-learning/discussions?sort=lastActivityAtDesc&amp;page=1">这里</a>可以找到。</p>
<h2 id="week-1">Week 1 机器学习介绍</h2>
<h3 id="what-is-machine-learning">What is Machine Learning?</h3>
<p>Two definitions of Machine Learning are offered. Arthur Samuel described it as: &ldquo;the field of study that gives computers the ability to learn without being explicitly programmed.&rdquo; This is an older, informal definition.</p>
<p>Tom Mitchell provides a more modern definition: &ldquo;A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.&rdquo;</p>
<p>Example: playing checkers.</p>
<ul>
<li>E = the experience of playing many games of checkers</li>
<li>T = the task of playing checkers.</li>
<li>P = the probability that the program will win the next game.</li>
</ul>
<h3 id="supervised-learning">Supervised learning</h3>
<blockquote>
<p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p>
<p>Supervised learning problems are categorized into &ldquo;regression&rdquo; and &ldquo;classification&rdquo; problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.</p>
</blockquote>
<ol>
<li>Supervised learning: 结果形式己知的机器学习。比如，从过往销售数据，预测未来三个月的销售数据。</li>
<li>Classfication learning: 输出结果是离散的。</li>
<li>Regression learning: 输出结果是连续的。</li>
</ol>
<h3 id="unsupervised-learning">Unsupervised learning</h3>
<blockquote>
<p>Unsupervised learning, on the other hand, allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don&rsquo;t necessarily know the effect of the variables.</p>
<p>With unsupervised learning there is no feedback based on the prediction results, i.e., there is no teacher to correct you. It’s not just about clustering.</p>
</blockquote>
<p>数据挖掘，从给定的数据集合里去发现规律，进行模式匹配。结果形式不可知。计算结果无法对数据进行反馈。</p>
<p><strong>例子：声音处理</strong><br />
从一个有背景音乐的吵杂的会议中演讲的录音文件中，通过数据挖掘和特征匹配来处理这段录音，最终分离出演讲录音和音乐。</p>
<ul>
<li>Supervised learning: Given email labed as spam/not spam; learn a email filter.</li>
<li>Unsupervised learning: Given as set of news articles found on web, group them as a set of articles about the same story.</li>
<li>Unsupervised learning: Given a set of customer data, automatically discover the market segment and group customers into different market segment.</li>
<li>Supervised learning: Given a dataset of patients diagnosed as either having diabets or not, learn to classify new patients as having diabets or not.</li>
</ul>
<h3 id="_2">线性回归算法</h3>
<ul>
<li>Cost Function: 成本函数，用来测量模型的准确度。成本函数把把建模问题转换为求成本函数的极小值。</li>
<li>Contour plots: 等高线。多参数的成本函数里，有一组参数的值会有相同的成本。这些参数联接起来就是成本函数的等高线。</li>
<li>Gradient Descent: 阶梯下降，假设的模型逐步逼近真实数据的过程</li>
</ul>
<p>REF:<br />
1. <a href="https://www.coursera.org/learn/machine-learning/supplement/Mc0tF/linear-regression-with-one-variable">Linear Regression with One Variable</a><br />
2. <a href="http://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables/189792#189792">Partial derivative in gradient descent for two variables</a></p>
<p>根据上面两个链接推导出阶梯下降函数。</p>
<h3 id="_3">数学</h3>
<ul>
<li><a href="http://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables/189792#189792">微积分</a> 四个最简单的规则<ul>
<li>针对 $F(x) = cx^n$，其导函数是 $F&rsquo;(x) = cn\times{x^{(n-1)}}$</li>
<li>常数的导数是 0</li>
<li>导函数可以穿透累加器，即 $\displaystyle\frac{\partial}{\partial x_0}\sum_{i=0}^nF(x_i) = \sum_{i=0}^n\frac{\partial}{\partial x_0}F(x_i)$</li>
<li>微分传导机制，即$\displaystyle\frac{\partial}{\partial x}g(f(x)) = g&rsquo;(f(x))\times f&rsquo;(x)$</li>
</ul>
</li>
<li><a href="https://www.coursera.org/learn/machine-learning/supplement/NMXXL/linear-algebra-review">线性代数</a></li>
<li><a href="https://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29#Derivation_of_the_normal_equations">最小二阶乘数拟合数据</a></li>
<li>概率论复习</li>
</ul>
<h3 id="_4">术语</h3>
<ul>
<li>Calculus: 微积分</li>
<li>Partial derivatives: 偏导数</li>
<li>Derivatives: 导数</li>
<li>Gradient Descent: 梯度下降</li>
<li>Cost Function: 成本函数</li>
<li>Contour plots: 等高线</li>
<li>Least Mean Squares: LSM, 最小均方</li>
</ul>
<h3 id="todo">TODO</h3>
<ul>
<li>使用 markdown + MathJax 来书写数学公式<ul>
<li><a href="http://mlworks.cn/posts/introduction-to-mathjax-and-latex-expression/">MathJax 简明中文教程</a> 这是一个质量很高的博客文章</li>
<li><a href="http://www.forkosh.com/mathtextutorial.html">LaTex 教程</a></li>
<li><a href="http://mirrors.ctan.org/info/symbols/math/maths-symbols.pdf">LaTex 支持的所有符号列表</a></li>
</ul>
</li>
<li>推导出模型参数的梯度下降公式 (Gradient Descent)</li>
<li>推导出 LSM (Widrow-Hoff学习算法)</li>
</ul>
<h2 id="week-2">Week 2 多变量梯度下降算法</h2>
<h3 id="_5">多变量梯度下降算法</h3>
<p>预测函数：<br />
$$<br />
h(\theta) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + &hellip; + \theta_n + x_n = \theta^T x^{(i)}<br />
$$<br />
其中，$x_0 = 1$，$x^{(i)}$ 是训练数据集里的第 i 个数据。$\theta_T$ 是 n + 1 维列向量；$x^{(i)}$ 是 n + 1 维行向量。</p>
<p>成本函数：<br />
$$<br />
J(\theta) = \frac{1}{2m} \sum_{(i=0)}^n \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2<br />
$$</p>
<p>迭代函数：<br />
$$<br />
\theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=0}^m \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)<br />
$$</p>
<h3 id="feature-scaling">变量缩放 Feature Scaling</h3>
<p>当变量在 [-1, 1] 这个范围内时，梯度下降算法能较快地收敛。可以使用下面的公式来缩放变量，以让变量在快速收敛的范围内：</p>
<p>$$<br />
x_i := \frac{x_i - \mu_i}{s_i}<br />
$$</p>
<p>其中，$\mu_i$ 是 $x_i$ 的平均值，即 $\mu_i = \frac{1}{n} \sum_{i=1}^n x_i$， $s_i$ 是 $x_i$ 的范围，即 $s_i = max(x_i) - min(x_i)$。</p>
<p>经过这样的转换，变量的范围全部落在 [-0.5, 0.5] 之间。</p>
<h3 id="_6">学习率</h3>
<p>使用 $\alpha$ 来表示学习率，值太高会导致无法收敛，太低收敛又太慢。一个好的办法是画出成本函数 $J(\theta)$ 随着迭代次数不断变化的曲线。这样可以直观地观察到随着迭代地不断进行，成本函数的值的变化情况。在实际情况中，可以从几个经验值里去偿试，比如 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1。</p>
<h3 id="normal-equalation">标准方程 Normal Equalation</h3>
<p>通过微分公式可以知道，我们要求成本函数 $J(\theta)$ 的最小值，只需要令其偏导数为零，即：<br />
$$<br />
\frac\partial{\partial{\theta_j}}J(\theta) := 0<br />
$$</p>
<p>把 $J(\theta)$ 用矩阵来表示，并根据矩阵运算定律最终可以推导出下面的方程式：</p>
<p>$$<br />
\theta = \left( X^T X \right)^{-1} X^T y<br />
$$</p>
<p>推导过程可参阅 <a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf">cs229-notes1.pdf</a>。推导过程会用到大量的矩阵运算知识。其中 X 是训练数据集，y 是结果数据向量。这样我们就可以通过直接计算的方式，而不是线性回归的方式来求得参数 $\theta$ 的值。</p>
<h3 id="octave">Octave 教程</h3>
<h4 id="octave_1">Octave 基本教程</h4>
<p>可以和 numpy, scipy 等结合起来学习。实际上接口较为类似。</p>
<h4 id="_7">向量化</h4>
<p>向量化可以让代码运算更简洁，效率更高。比如，我们的预测函数的普通形式可以写成：</p>
<p>$$<br />
h_\theta(x) = \sum_{i=0}^{n} \theta_ix^{(i)}<br />
$$</p>
<p>那么其 Octave 代码如下：</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">prediction = <span style="color: #666666">0.0</span>
<span style="color: #AA22FF; font-weight: bold">for</span> <span style="color: #AA22FF">i</span>=<span style="color: #666666">1</span>:n<span style="color: #666666">+1</span>,
    prediction = predicition <span style="color: #666666">+</span> theta(<span style="color: #AA22FF">i</span>) <span style="color: #666666">*</span> x(<span style="color: #AA22FF">i</span>)
<span style="color: #AA22FF; font-weight: bold">end</span>;
</pre></div>


<p>我们也可以把预测函数向量化：</p>
<p>$$<br />
h_\theta(x) = \theta^T x<br />
$$</p>
<p>这样，我们的预测函数可以实现如下：</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">prediction = theta<span style="color: #666666">&#39;</span> <span style="color: #666666">*</span> x
</pre></div>


<p>另外一个例子是梯度下降算法里的参数迭代函数：</p>
<p>$$<br />
\theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) -y^{(i)} \right) x_j^{(i)}<br />
$$</p>
<p>我们可以向量化为：</p>
<p>$$<br />
\theta = \theta - \alpha \delta<br />
$$</p>
<p>其中，$\theta$ 是个 n + 1 维向量；$\alpha$ 是一个标量；$\delta$ 是一个 n + 1 维向量。$\delta$ 可以向量化为：</p>
<p>$$<br />
\delta = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) - y^{(i)} \right) x^{(i)}<br />
$$</p>
<p>其中，$\left( h_\theta(x^{(i)}) - y^{(i)} \right)$ 是个标量；$x^{(i)}$ 是个 n + 1 维向量，其行元素为 $x^{(i)}_0, x^{(i)}_1, x^{(i)}_2 &hellip; x^{(i)}_n$，其上标为第 i 项训练样例数据，下标为第 j 项变量；而 m 项求和，实际上可以看成是一个线性方程组的表达形式。</p>
<h4 id="_8">标准方程和奇异矩阵</h4>
<p>$$<br />
\theta = (X^T X)^{-1} X^T y<br />
$$</p>
<p>这是我们的通用方程，当训练数据集较少时，利用矩阵运算可以较快的算出参数 $\theta$ 的值。但如果 $X^T X$ 是奇异矩阵的话，它就没有逆矩阵存在，这个时候通用方程的解是什么呢？答案是，在 octave 里用 <code>pinv</code> 来代替 <code>inv</code> 来计算逆矩阵。这样即使 $X^T X$ 是奇异矩阵，<code>pinv</code> 也能算出其&rdquo;伪&rdquo;逆矩阵，从而顺利算出通用方向的解。</p>
<p>那么，物理上讲，$X^T X$ 如果为奇异矩阵的话，到底代表什么意思呢？</p>
<ul>
<li>模型变量之间线性相关<br />
  比如，在房价预测模型里，$x_1$ 代表房子的长度，$x_2$ 代表房子的宽度，而 $x_3$ 代表房子的面积，这里假设房子是方形的，那么实际上 $x_3$ 和 $x_1, x_2$ 是线性相关的。</li>
<li>训练样例少于变量个数，即 m &lt; n<br />
  这种情况下，需要减少变量个数来解决问题</li>
</ul>
<h3 id="todo_1">TODO</h3>
<ol>
<li>如何从数学上证明变量绽放后能较快收敛？</li>
<li>可以使用 <code>pylab</code> 的等高线在二维平面上画出成本函数和两个参数的关系图</li>
<li>找一个数据集，选择不同的学习率来实现，画出不同学习率时的成本函数随着迭代次数的变化情况</li>
<li>总结 matlab/octave 和 scipy/numpy 在数值计算上的差异和优缺点</li>
</ol>
<h2 id="week-3-logistic-regression">Week 3 分类回归算法 Logistic Regression</h2>
<h3 id="classification-and-representation">分类预测函数及其表现形式 Classification and Representation</h3>
<h4 id="_9">引言 为什么需要分类回归算法</h4>
<p>分类问题的值是离散的，如果考虑二元分类总是，则其值是 0 或 1。如果用 linear regresstion 来作为分类问题的预测函数是不合理的。因为因为预测出来的数值可能远小于 0 或远大于 1。我们需要找出一个预测函数模型，使其值的输出在 [0, 1] 之间。</p>
<h4 id="hypothesis-representation">逻辑回归预测函数的表现形式 Hypothesis Representation</h4>
<p><strong>逻辑回归预测函数</strong></p>
<p>线性回归算法的预测函数是 $h_\theta(x) = \theta^T x$，为了让预测函数的输出值在 [0, 1] 之间，我们给定逻辑回归模型 (Logistic Regression Model) $g(z) = \frac{1}{1 + e^{-z}}$，则我们的逻辑回归模型的预测函数如下：</p>
<p>$$<br />
h_\theta(x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^T x}}<br />
$$</p>
<p><strong>解读逻辑回归预测函数的输出值</strong></p>
<p>$h_\theta(x)$ 表示针对输入值 $x$ 以及参数 $\theta$ 的前提条件下，$y=1$ 的概率。用概率论的公式可以写成：</p>
<p>$$<br />
h_\theta(x) = P(y=1 \vert x; \theta)<br />
$$</p>
<p>上面的概率公式可以读成：<strong>在输入 $x$ 及参数 $\theta$ 条件下 $y=1$ 的概率</strong>。由概率论的知识可以推导出，</p>
<p>$$<br />
P(y=1 \vert x; \theta) + P(y=0 \vert x; \theta) = 1<br />
$$</p>
<h4 id="decision-boundary">判定边界 Decision Boundary</h4>
<p><strong>从逻辑回归公式说起</strong></p>
<p>逻辑回归预测函数由下面两个公式给出的：</p>
<p>$$<br />
h_\theta(x) = g(\theta^T x)<br />
$$</p>
<p>$$<br />
g(z) = \frac{1}{1 + e^{-z}}<br />
$$</p>
<p>假定 $y=1$ 的判定条件是 $h_\theta(x) \geq 0.5$，$y=0$ 的判定条件是 $h_\theta(x) &lt; 0.5$，则我们可以推导出 $y=1$ 的判定条件就是 $\theta^T x \geq 0$，$y=0$ 的判定条件就是 $\theta^T x &lt; 0$。所以，$\theta^T x = 0$ 即是我们的判定边界。</p>
<p><strong>判定边界</strong></p>
<p>假定我们有两个变量 $x_1, x_2$，其逻辑回归预测函数是 $h_\theta(x) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2)$。假设我们给定参数</p>
<p>$$<br />
\theta = \begin{bmatrix} -3 \\ 1 \\ 1 \end{bmatrix}<br />
$$</p>
<p>那么我们可以得到判定边界 $-3 + x_1 + x_2 = 0$，即 $x_1 + x_2 = 3$，如果以 $x_1$ 为横坐标，$x_2$ 为纵坐标，这个函数画出来就是一个通过 (0, 3) 和 (3, 0) 两个点的斜线。这条线就是我们的判定边界。</p>
<p><strong>非线性判定边界</strong></p>
<p>如果预测函数是多项式 $h_\theta(x) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2)$，且给定 $\theta^T = \left[ -1 0 0 1 1\right]$，则可以得到判定边界函数</p>
<p>$$<br />
x_1^2 + x_2^2 = 1<br />
$$</p>
<p>还是以 $x_1$ 为横坐标，$x_2$ 为纵坐标，则这是一个半径为 1 的圆。这是二阶多项式的情况，更一般的多阶多项式可以表达出更复杂的判定边界。</p>
<h3 id="_10">逻辑回归的成本函数</h3>
<p>线性回归的成本函数是 $J(\theta) = \frac{1}{m} \sum_{i=1}^m \frac{1}{2} \left (h_\theta(x^{(i)}) - y^{(i)} \right)^2 $，如果我们按照线性回归的成本函数来计算逻辑回归的成本函数，那么我们最终会很可能会得到一个非凸函数 (non-convex function)，这样我们就无法通过梯度下降算法算出成本函数的最低值。</p>
<p>为了让成本函数是个凸函数 (convex function)，以便容易求出成本函数的最小值，我们定义逻辑回归的成本函数如下：</p>
<p>$$<br />
Cost(h_\theta(x), y) = \begin{cases}<br />
    -log(h_\theta(x)), &amp; \text{if $y$ = 1} \\<br />
    -log(1 - h_\theta(x)), &amp; \text{if $y$ = 0} \\<br />
\end{cases}<br />
$$</p>
<p><strong>成本函数的解读</strong><br />
如果 $y = 1, h_\theta(x) = 1$，那么成本为 $Cost = 0$；如果 $y = 1, h_\theta(x) \rightarrow 0$，那么成本将是无穷大 $Cost \rightarrow \infty$。<br />
如果 $y = 0, h_\theta(x) = 0$，那么成本为 $Cost = 0$；如果 $y = 0, h_\theta(x) \rightarrow 1$，那么成本将是无穷大 $Cost \rightarrow \infty$。</p>
<h4 id="_11">逻辑回归成本函数定义</h4>
<p>由于 $y \in [0, 1]$ 的离散值，可以把两个成本函数合并起来：</p>
<p>$$<br />
J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)})) \right]<br />
$$</p>
<p>把 $y = 0, y = 1$ 两种情况代入上式，很容易可以验证成本函数合并的等价性。使用梯度下降算法进行参数迭代的公式如下：</p>
<p>$$<br />
\begin{align}<br />
\theta_j &amp; = \theta_j - \alpha \frac\partial{\partial{\theta_j}}J(\theta) \\<br />
&amp; =  \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)}<br />
\end{align}<br />
$$</p>
<p>这个公式的形式和母性回归算法的参数迭代公式是一样的。当然，由于这里 $h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}$，而线性回归算法里 $h_\theta(x) = \theta^T x$。所以，两者的形式一样，但数值计算完全不同。</p>
<h3 id="_12">算法优化</h3>
<p>梯度下降算法的效率是比较低，优化的梯度下降算法有 Conjugate Gradient, BFGS, L-BFGS 等。这些算法比较复杂，实现这些算法是数值计算专家的工作，一般工程人员只需要大概知道这些算法是怎么优化的以及怎么使用这些算法即可。</p>
<p>octave 里提供了 <code>fminunc</code> 函数，可以查阅文档来学习函数用法，从而学会使用优化过的梯度下降算法，以提高计算效率。</p>
<h3 id="_13">多元分类算法</h3>
<p>除了二元分类算法外，还有多元分类问题，比如需要给邮件打标签，则可能有多个标签需要考虑。这个时候需要使用 one-vs-all (one-vs-rest) 的方法。即把要分类的一种类别和其他所有类别区分开来的，这样就把多元分类问题转化为二元分类问题，这样就可以使用上文总结的所有二元分类问题的算法。</p>
<p>针对 $y = i$，求解针对 i 的预测函数 $h_\theta^{(i)}(x)$。如果有 n 个类别，则需要求解 n 个预测函数。</p>
<h3 id="regularization">正则化 Regularization</h3>
<h4 id="_14">线性回归里的欠拟合和过拟合</h4>
<ul>
<li>欠拟合 (underfitting)<br />
  使用的变量过少导致成本函数过高。</li>
<li>过拟合 (overfitting)<br />
  使用多个变量建模的预测函数非常完美地拟合了数据，其成本函数的值接近于零，但无法对新的实例进行良好的预测。</li>
</ul>
<p><strong>变量太多，而训练样本数据太少，则很可能出现过拟合</strong>。下面是一些解决过拟合问题的方法：</p>
<ul>
<li>减少变量个数<ul>
<li>手动减少变量个数</li>
<li>模型选择算法</li>
</ul>
</li>
<li>正则化<ul>
<li>保留所有的变量，去所有变量的权重 $\theta_j$ 的值</li>
<li>当每个变量 $x_i$ 对预测值 $y$ 都有少量的贡献时，这样的模型可以良好地工作</li>
</ul>
</li>
</ul>
<p>这就是正则化的目的，为了解决变量过多时的过拟合问题。</p>
<h4 id="_15">正则化</h4>
<p>$$<br />
J(\theta) = \frac{1}{2m} \left[ \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2 + \lambda \sum_{j=1}^n \theta_j^2 \right]<br />
$$</p>
<p>其中 $\lambda$ 的值有两个目的，即要维持对训练样本的拟合，又避免对训练样本的过拟合。如果 $\lambda$ 太大，则能确保不出现过拟合，但可能会导致对现有训练样本出现欠拟合。</p>
<p>利用正则化的成本函数，可以推导出参数迭代函数：</p>
<p>$$<br />
\begin{align}<br />
\theta_j &amp; = \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m \left[ \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right) + \frac{\lambda}{m} \theta_j \right] \\<br />
&amp; = \theta_j (1 - \alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i=1}^m \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)<br />
\end{align}<br />
$$</p>
<p>$(1 - \alpha \frac{\lambda}{m})$ 因子在每次迭代时都将把 $\theta_j$ 收缩。因为 $\alpha$ 和 $\lambda$ 是正数，而 m 是训练样例的个数，是个比较大的正整数。</p>
<h4 id="_16">通用方程的正则化</h4>
<p>$$<br />
\theta = (X^T X)^{-1} X^T y<br />
$$</p>
<p>这是还没有正则化的通用方程，我们用它来快速求解。</p>
<p>$$<br />
\theta = (X^T X + \lambda Z)^{-1} X^T y<br />
$$</p>
<p>其中，Z 是 (n + 1) x (n + 1) 矩阵</p>
<p>$$<br />
Z =<br />
\begin{bmatrix}<br />
0 \\<br />
&amp; 1 \\<br />
&amp; &amp; 1 \\<br />
&amp; &amp; &amp; \ddots \\<br />
&amp; &amp; &amp; &amp; 1<br />
\end{bmatrix}<br />
$$</p>
<p>正则化的通用方程实际上解决了两个问题。一个是确保不发生过拟合，另外一个也解决了 $X^T X$ 的奇异矩阵问题。当 m &lt; n 时，$X^T X$ 将是一个奇异矩阵，使用 octave 里的 <code>pinv</code> 函数我们可以求出近似逆矩阵的值，但如果在其他编程语言里，是没有办法求出奇异矩阵的逆矩阵的。而从数学上可以证明，加上 $\lambda Z$ 后，结果将是一个非奇异矩阵。</p>
<p>通用方程的正则化公式推导过程复杂，过程从略。</p>
<h4 id="_17">逻辑回归成本函数的正则化</h4>
<p>$$<br />
J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)})) \right] + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2<br />
$$</p>
<p>相应地，正则化后的参数迭代公式</p>
<p>$$<br />
\begin{align}<br />
\theta_j &amp; = \theta_j - \alpha \frac\partial{\partial{\theta_j}}J(\theta) \\<br />
&amp; = \theta_j - \alpha \left[ \frac{1}{m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)} + \frac{\lambda}{m} \theta_j \right] \\<br />
&amp; = \theta_j (1 - \alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i=1}^m \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)<br />
\end{align}<br />
$$</p>
<p>需要注意的是，上式中 $j \geq 1$，因为 $\theta_0$ 没有参与正则化。另外需要留意，逻辑回归和线性回归的参数迭代算法看起来形式是一样的，即公式 (4) 和公式 (7) 形式一样，但其实他们的算法是不一样的，因为两个式子的预测函数 $h_\theta(x)$ 是不一样的。针对线性回归，$h_\theta(x) = \theta^T x$，而针对逻辑回归 $h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}$。</p>
<p>根据正则化的，新的成本函数的参数迭代函数来实现 CostFunction，然后利用 octave 里的 <code>fminunc</code> 函数来求解，这样可以达到最高的运算效率。因为 <code>fminunc</code> 会使用优化过的梯度下降算法 Conjugate Gradient, BFGS, L-BFGS 等来提高运算效率。</p>
<blockquote>
<p>学到这里，你基本上可以使用线性回归逻辑回归解决一些现实问题了。我看到硅谷有大量的公司使用机器算法来构建伟大的产品，那些机器学习工程师在这些公司获得了很好的职业发展并且赚了不少钱。&mdash; Andrew Ng</p>
</blockquote>
<p>老师除了教得好，还要会鼓励，让学生保持学习的热情和兴趣。学完三周，瞬间高大上了，可以走上硅谷机器学习工程师的职业道路了~~。我的看法是，学到了不少知识，但依然任重道远。</p>
<h3 id="todo_2">TODO</h3>
<ol>
<li>使用 pylab/octave 画出逻辑回归预测函数的图形</li>
<li>是否有类似 MathJax 类似的，使用 JavaScript 来在网页上画图的库呢？<a href="http://stackoverflow.com/questions/119969/javascript-chart-library">这里</a>有个相似的问题。</li>
<li>复习<a href="http://cs229.stanford.edu/section/cs229-prob.pdf">概率论</a>基础知识</li>
<li>使用 pylab/octave 画出逻辑回归成本函数的图形</li>
<li>复习微积分知识，推导出逻辑回归算法的参数迭代函数</li>
<li>理解 Conjugate Gradient, BFGS, L-BFGS 的原理</li>
<li>查阅 octave 文档学习 <code>fminunc</code> 函数以及 scipy 里对应的函数</li>
<li>通用方程的正则化的数学推导过程</li>
</ol>
<h2 id="week-4-neural-networks-presentation">Week 4 神经网络表示 Neural Networks: Presentation</h2>
<h3 id="motivations">动机 Motivations</h3>
<p>为什么我们需要神经网络？</p>
<p>对非线性分类问题，当特征的个数很大的时候，计算量将会非常大。比如对有 100 个特征（$x_1, x_2, \cdots, x_100$）的问题，如果我们只算二阶多项多项式，我们将得到大概 5000 个特征 ($O(n^2)$)。而如果按照三阶多项式来模拟，将得到将近 300,000 个特征 ($O(n^3)$)。再比如，针对一个 100 x 100 分辨率的图片，我们假设每个象素点只用黑白来表示，那么将得到 100,000 个特征值。这个时候如果用二阶多项式来拟合，我们将得到 50,000,000,000 个特征值组合。这是非常巨大的计算量。</p>
<p>显然，用线性回归和逻辑回归来解决这类问题是不现实的。</p>
<h3 id="_18">神经网络模型</h3>
<p>神经网络模型是依照大脑的神经网络的结构建模的。即多个神经元构成一个层，这些神经元是输入，层的目标值为输出。一个神经网络包含多个层。神经元是神经网络中的运算单位。</p>
<h4 id="_19">神经元</h4>
<p>神经元是神经网络中的最小运算单位，多个神经元构成一个层。神经网络依然使用逻辑回归算法里介绍的 Sigmoid Function 作为基本模型。</p>
<p>$$<br />
g(z) = \frac{1}{1 + e^{-z}} \\<br />
z = \theta^T x \\<br />
h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}<br />
$$</p>
<p>其中，$x$ 称作神经元的输入 (input wires or Dendrite)，是个列向量 $[x_1, x_2, &hellip; x_n]$。$\theta$ 称为权重 (weights)，也可以类似逻辑回归里称为参数 (parameters)。$h_\theta(x)$ 称为输出 (output wires or Axon)。这个是神经网络模型中的基本运算单元。</p>
<p>类似逻辑回归，我们也会增加一个输入 $x_0$，在这里称作偏置单元 (bias unit)。</p>
<h4 id="_20">神经网络</h4>
<p>神经网络可以划分成多个层，每个层有一定数量的神经元。其中第一层叫输入层，最后一层叫输出层，一个或多个中间层叫隐藏层。</p>
<p><img alt="neural networks" src="https://raw.githubusercontent.com/kamidox/blogs/master/images/neural_networks.png" /></p>
<p><strong>几个索引的含义</strong></p>
<p>$a_i^{(j)}$: 表示第 j 层的第 i 个神经元 unit i in layer j<br />
$\Theta^{(j)}$: 控制神经元网络中从第 j 层转化到第 j + 1 层的权重矩阵。这个矩阵里的元素经常写成 $\Theta_{ik}^{(j)}$ 其中 j 表示第 j 层，i 表示第 j 层神经元的单元索引值，k 表示第 j 层第 i 个神经元的输入项索引值。</p>
<p>$$<br />
a_1^{(2)} = g(\Theta_{10}^{(1)} x_0 + \Theta_{11}^{(1)} x_1 + \Theta_{12}^{(1)} x_2 + \Theta_{13}^{(1)} x_3) \\<br />
a_2^{(2)} = g(\Theta_{20}^{(1)} x_0 + \Theta_{21}^{(1)} x_1 + \Theta_{22}^{(1)} x_2 + \Theta_{23}^{(1)} x_3) \\<br />
a_3^{(2)} = g(\Theta_{30}^{(1)} x_0 + \Theta_{31}^{(1)} x_1 + \Theta_{32}^{(1)} x_2 + \Theta_{33}^{(1)} x_3) \\<br />
h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)} a_0 + \Theta_{11}^{(2)} a_1 + \Theta_{12}^{(2)} a_2 + \Theta_{13}^{(2)} a_3)<br />
$$</p>
<p>假设 j 层有 $s_j$ 个单元，j + 1 层有 $s_{j+1}$ 个单元。那么 $\Theta^{(j)}$ 将是一个 $s_{j+1}$ x $(s_j + 1)$ 的矩阵。</p>
<h4 id="forward-propagation-vectorized-implementation">向前传播算法的向量化实现 Forward Propagation: Vectorized Implementation</h4>
<p>$$<br />
let: z_1^{(2)} = \Theta_{10}^{(1)} x_0 + \Theta_{11}^{(1)} x_1 + \Theta_{12}^{(1)} x_2 + \Theta_{13}^{(1)} x_3 = \Theta^{(1)} x \\<br />
\Rightarrow a_1^{(2)} = g\left( z_1^{(2)} \right) \\<br />
a_2^{(2)} = g\left( z_2^{(2)} \right) \\<br />
a_3^{(2)} = g\left( z_3^{(2)} \right) \\<br />
\Rightarrow a^{(2)} = g\left( z^{(2)} \right) \\<br />
z^{(3)} = \Theta^{(2)} a^{(2)} \\<br />
\Rightarrow h_\Theta(x) = a^{(3)} = g\left( z^{(3)} \right)<br />
$$</p>
<p>更一般的情况，假设待训练的数据集 $X$ 是 m x n 矩阵，记作 $X \in R^{m \times n}$，其中 m 是数据集个数，n 是输入的特征数，此处假设 $X$ 里已经加入了偏置单元 (bias unit)。假设隐藏层有 s2 个单元，$\Theta^{(1)}$ 为输入层到隐藏层的转换参数。则 $\Theta^{(1)} \in R^{s2 \times n}$。输出层有 s3 个单元，$\Theta^{(2)}$ 为隐藏层到输出层的转换参数。则 $\Theta^{(2)} \in R^{s3 \times (s2 + 1)}$。我们记 $a^{(2)}$ 为隐藏层，$a^{(3)}$ 为输出层，则：</p>
<p>$$<br />
a^{(2)} = g\left( X * \left( \Theta^{(1)} \right)^T \right)<br />
$$</p>
<p>算出后，给 $a^{(2)}$ 加上偏置单元。为了书写方便，此处我们仍然将加上偏置单元后的隐藏层记作 $a^{(2)}$。则：</p>
<p>$$<br />
a^{(3)} = g\left( a^{(2)} * \left( \Theta^{(2)} \right)^T \right)<br />
$$</p>
<p>这几个公式就是神经网络向量化运算的重要规则。其中 $g(z) = \frac{1}{1 + e^{-z}}$ 是 Sigmoid Function。</p>
<p><strong>神经网络通过学习来决定其特征</strong></p>
<p>单单从 $h_\Theta(x) = g\left(\Theta^{(2)} a^{(2)}\right)$ 式子来看，神经网络的输出就是由特征 $a_1^{(2)}, a_2^{(2)}, a_3^{(2)}$ 的逻辑回归模型表述的。但这里的每个特征 $a_1^{(2)}, a_2^{(2)}, a_3^{(2)}$ 都是分别由 $x_1, x_2, x_3$ 的逻辑回归模型学习出来的。这就是神经网络的精髓所在。</p>
<h3 id="_21">神经网络的应用实例</h3>
<h4 id="_22">运用神经网络来模拟逻辑运算</h4>
<p>假设 $\Theta = [-30, 20, 20]$，</p>
<p>$$<br />
h_\Theta(x) = g(\Theta^T x) = g(-30 + 20x_1 + 20x_2)<br />
$$</p>
<p>$g(z)$ 是 Sigmoid Function，其图形近似于 S 形。假设 $x_1, x_2 \exists {0, 1}$ 是逻辑值。当 $x_1 = 0, x_2 = 0$ 时，$h_\Theta(x) = g(-30) \approx 0$。同理可以写出下面的真值表：</p>
<table>
<thead>
<tr>
<th>x_1</th>
<th>x_2</th>
<th>h(x)</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>这样就模拟了逻辑 AND 的运算，即 h(x) = x1 AND x2。同理可以推算出当 $\Theta = [-10, 20, 20]$ 时，h(x) = x1 OR x2。还可以推断出当 $\Theta = [10, -20, -20]$ 时，h(x) = (NOT x1) AND (NOT x2)。当需要计算 x1 NXOR x2 时，可以用神经网络模型，即 x1 NXOR x2 = (x1 AND x2) OR ((NOT x1) AND (NOT x2))。我们把 x1, x2 当作输入，a1 = (x1 AND x2), a2 = (NOT x1) AND (NOT x2) 当作隐藏层，而最终的输出由 a1 OR a2 来计算得来了。</p>
<h4 id="_23">运用神经网络来处理多类别的分类问题</h4>
<p>上文介绍的神经网络只能输出入 0, 1 二元问题。扩展到多个类别时，我们输出一个向量，比如针对最终结果是四种类别的问题时，输出 [1, 0, 0, 0] 表示第一种类别，输出 [0, 1, 0, 0] 表示是第二种类别，依此类推。</p>
<p>问题：为什么不用 1, 2, 3, 4 四个不同的值来表示四种类别，而要用一个四维的向量来表示？</p>
<h2 id="week-5-neural-networks-learning">Week 5 神经网络学习 Neural Networks: Learning</h2>
<h3 id="_24">成本函数</h3>
<p>针对分类问题的神经网络的输出层</p>
<p>$$<br />
h_\Theta(x) \in R^K; \left( h_\Theta(x) \right)_k = k^{th} output<br />
$$</p>
<p>其中 K 是输出层的的单元个数，K &gt;= 3。因为如果 K &lt; 3 则可以直接用一个单元表示。其成本函数是：</p>
<p>$$<br />
J(\Theta) = - \frac{1}{m} \left[ \sum_{i=1}^m \sum_{k=1}^K y_k^{(i)} log(h_k^{(i)}) + (1 - y_k^{(i)}) log(1 - h_k^{(i)}) \right] + \frac{\lambda}{2m} \sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} (\Theta_{ji}^{(l)})^2<br />
$$</p>
<p>其中 $h_k^{(i)} = {h_\Theta(x^{(i)})}_k$ 是 $k^{th}$ 层针对 $i^{th}$ 训练样本的预测值。$L$ 是神经网络的层数，$s_l$ 是指第 $l$ 层的单元个数。公式的前半部分是未正则化的成本函数，后半部分是正则项，加起来就是正则化的成本公式。注意正则项部分求和时是从 $i=1$ 开始的，即我们不把偏置变量正则化。</p>
<div class="admonition warnning">
<p class="admonition-title">MathJax 的缺陷</p>
<p>这个公式我写了 20 分钟。它已经复杂到我不得不把 $h_k^{(i)}$ 独立写出来了，如果全部写一个公式里，公式将无法正确显示。不服的可以自己试看看。</p>
</div>
<p><strong>编程时怎么解读正则项呢？</strong></p>
<p>正则项有三个累加器，最前面那个是层累加器，典型地，对 3 层神经网络模型 $L=3$。所以正则项简化为：</p>
<p>$$<br />
reg = \frac{\lambda}{2m} \left( \sum_{i=1}^{s_1} \sum_{j=1}^{s_2} \left( \Theta_{ji}^{(1)} \right)^2 + \sum_{i=1}^{s_2} \sum_{j=1}^{s_3} \left( \Theta_{ji}^{(2)} \right)^2 \right)<br />
$$</p>
<h3 id="_25">向后传播算法</h3>
<p>我们把 $\delta_j^{(l)}$ 记作神经网络中第 $l$ 层，第 $j$ 个节点的误差。针对输出层，我们有</p>
<p>$$<br />
\delta_j^{(L)} = a_j^{(L)} - y_j<br />
$$</p>
<p>按照向量化写法，我们得到</p>
<p>$$<br />
\delta^{(L)} = a^{(L)} - y<br />
$$</p>
<p>此由可见，$\delta^{(L)}$ 是和 $y$ 一样维度的向量。针对第 $L-1$ 层，我们把误差定义为</p>
<p>$$<br />
\delta^{(L-1)} = (\Theta^{(L-1)})^T \delta^{(L)} .* g&rsquo;(z^{(L-1)})<br />
$$</p>
<p>可以从数学上证明 $g&rsquo;(z^{(L-1)}) = a^{(L-1)} .* (1 - a^{(L-1)})$ 成立。这样我们算出输出层的误差，然后一层层往前推导，算出各层的误差，就是我们向后传播算法名字的由来。需要注意的是，不存在 $\delta^{(1)}$，因为神经网络的第 1 层是我们的输入项，不存在误差问题。</p>
<p>从数学上可以证明，如果忽略正则项，即 $\lambda = 0$时</p>
<p>$$<br />
\frac{\partial}{\partial \Theta_{ij}^{(l)}} J(\Theta) = a_j^{(l)} \delta_i^{(l+1)}<br />
$$</p>
<p><strong>注意</strong>：</p>
<ol>
<li>计算微分项时，只需要计算 1, 2, &hellip;, l+1 层的微分项</li>
<li>微分项 $\frac{\partial}{\partial \Theta_{ij}^{(l)}} J(\Theta)$ 是个和 $\Theta^{(l)}$ 尺寸相同的矩阵</li>
</ol>
<p>最后，针对训练样本 ${ (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), &hellip; (x^{(m)}, y^{(m)}),}$，我们可以把向后传播算法用伪代码描述如下：</p>
<ul>
<li>初始化误差累加值 set $\Delta_{ij}^{(l)} = 0$, for all $l, i, j$</li>
<li>遍历所有的训练样本 for i = 1 to m<ul>
<li>设置输入层的激励为第 $i$ 个训练样本的输入值 set $a^{(1)} = x^{(i)}$</li>
<li>使用向前扩散公式 $a^{(l+1)} = g\left( a^{(l)} * \left( \Theta^{(l)} \right)^T \right)$，算出所有层的激励 $a^{(l)}$ for $l = 2, 3, &hellip; , L$</li>
<li>使用输出层的激励，计算输出层的误差 $\delta^{(L)} = a^{(L)} - y^{(i)}$</li>
<li>使用反向扩散的方法 $\delta^{(L-1)} = (\Theta^{(L-1)})^T \delta^{(L)} .* g&rsquo;(z^{(L-1)})$ 计算每一层的误差 $\delta^{(L-1)}, \delta^{(L-2)}, &hellip;, \delta^{(2)}$。</li>
<li>累加 $(x^{(i)}, y^{(i)})$ 训练样本的误差 $\Delta_{ij}^{(l)} = \Delta_{ij}^{(l)} + a_j^{(l)} \delta_i^{(l+1)}$。</li>
</ul>
</li>
<li>endfor</li>
<li>累加的值除以 m 即得到无正则化的微分项 $\frac{\Delta_{ij}^{(l)}}{m}$</li>
</ul>
<p>最后一项可以用向量化的写法：</p>
<p>$$<br />
\Delta^{(l)} = \Delta^{(l)} + \delta^{(l+1)} \left( a^{(l)} \right)^T<br />
$$</p>
<p><strong>注意</strong>:<br />
<strong>计算过程中，需要注意偏置单元。根据惯例，累加时不计算偏置单元。针对反向扩散公式 $\delta^{(L-1)} = (\Theta^{(L-1)})^T \delta^{(L)} .* g&rsquo;(z^{(L-1)})$，需要特别注意矩阵运算时的维度需要匹配。</strong></p>
<p>加入正则项后，我们有</p>
<p>$$<br />
D_{ij}^{(l)} = \frac{1}{m} \Delta_{ij}^{(l)} + \frac{\lambda}{m} \Theta_{ij}^{(l)}, if j \ne 0<br />
$$<br />
$$<br />
D_{ij}^{(l)} = \frac{1}{m} \Delta_{ij}^{(l)}, if j = 0<br />
$$</p>
<p>从数学上可以证明</p>
<p>$$<br />
\frac{\partial}{\partial \Theta_{ij}^{(l)}} J(\Theta) = D_{ij}^{(l)}<br />
$$</p>
<p>这样我们就算出来了神经网络模型的成本函数微分项。有了成本函数和成本函数微分项，我们就可以使用线性回归或其他高级算法来计算神经网络成本函数的最小值，从而求解神经网络中各层激励的参数。</p>
<h3 id="backpropagation-in-practice">实践中的向后传播算法 Backpropagation in Practice</h3>
<h4 id="_26">参数折叠</h4>
<p>在线性回归或逻辑回归算法里，我们的参数是向量，我们使用的 <code>fminunc</code> 等函数也只接受向量作为参数。而神经网络算法里，参数是个向量，$\Theta^{(l)} \in R^{s_{l+1}, s_l + 1}$。所以，在训练神经网络算法时，需要对参数进行折叠，即把矩阵转换为大向量，而在使用时，可以再转换回为矩阵。</p>
<p>假设 Theta1 是 10x11 的矩阵，它是第一层的参数； Theta2 是 10x11 的矩阵，它是第二层的参数。可以使用下面的 matlab/octave 来转换：</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">ThetaVec = [Theta1(:); Theta2(:)];
</pre></div>


<p>在成本函数函数里，我们需要转换为矩阵进行计算：</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">Theta1 = reshape(ThetaVec(1:110), 10, 11);
Theta2 = reshape(ThetaVec(111:220), 10, 11);
</pre></div>


<p>同理，针对成本函数的微分项，$D^{(1)} \in R^{10x11}, D^{(2)} \in R^{10x11}$，我们的成本函数返回这个微分项时，也需要把矩阵转换为向量：</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">DVec = [D1(:); D2(:)]
</pre></div>


<h4 id="_27">微分项检验</h4>
<p>神经网络的微分项特别复杂，有时候一些小的错误可能不会导致算法失败，这样就很难发现问题。这里介绍一个方法来验证微分项算法是否正确。我们使用的是微分的数值估算方法。</p>
<p>$$<br />
\frac{d}{d\theta} J(\theta) \approx \frac{J(\theta + \varepsilon) + J(\theta - \varepsilon)}{2 \varepsilon}<br />
$$</p>
<p>这里只要 $\varepsilon$ 足够小，则可以近似地计算出微分项的值。实际计算时，我们一般取 $varepsilon = 0.0001$。这样算出来的值和微分项算出来的值应该非常近似，用这个方法我们可以验证微分项计算是否准确。<strong>需要特别注意的是，在验证完微分项计算的正确性后，数值近似计算必须关闭掉。否则会使算法效率严重降低。</strong>因为数值计算的成本是很高的。</p>
<p><strong>编程时需要注意</strong></p>
<p>微分项检查实际上是一种纯数学的做法。主要是检查我们使用 backpropagation 方法算出来的微分和用数值计算算出来的微分是否相同。它适用于其他算法，如线性回归或逻辑回归算法。有几点需要特别注意。</p>
<ul>
<li>由于计算很费时间，实际检查时，$\theta$ 可以选小一点的矩阵，比如 3 x 5，而不需要使用真正的机器学习时的 theta。因为 $\theta$ 太大不但费时间，还不利于观察。</li>
<li>实际计算时，$\theta$ 往往是个列向量。这个时候我们需要让 $\varepsilon$ 也是一个和 $\theta$ 维度相同的向量，其值你还记得吗为 0 。当检查 $\theta(i)$ 元素的偏微分项时，让 $\varepsilon$ 的的第 i 项的值为 0.0001，其他项都为 0 。这样进行矩阵来进行数值微分计算。</li>
</ul>
<h4 id="_28">用随机数初始化参数</h4>
<p>在进行线性回归和逻辑回归计算时，我们把参数全部初始化为零。但这个做法在神经网络里是不可行的，如果我们把参数全部初始化为零，那么隐藏层的神经单元的激励 $a_i^{(l)}$ 将是相同的，其误差 $\delta_i^{(l)}$ 也将是相同的，即我们计算的全部是相同的特征，这样神经网络就失去了其特征的覆盖度和丰富性。</p>
<p>所以，我们需要把神经网络的每个参数 $\Theta_{ij}^{(l)}$ 初始化为 $[-\varepsilon, \varepsilon]$ 之间的一个随机数。例如：</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">Theta1 = <span style="color: #AA22FF">rand</span>(<span style="color: #666666">10</span>, <span style="color: #666666">11</span>) <span style="color: #666666">.*</span> (<span style="color: #666666">2</span> <span style="color: #666666">.*</span> INIT_VAREPSILON) <span style="color: #666666">-</span> INIT_VAREPSILON;
Theta2 = <span style="color: #AA22FF">rand</span>(<span style="color: #666666">10</span>, <span style="color: #666666">11</span>) <span style="color: #666666">.*</span> (<span style="color: #666666">2</span> <span style="color: #666666">.*</span> INIT_VAREPSILON) <span style="color: #666666">-</span> INIT_VAREPSILON;
Theta3 = <span style="color: #AA22FF">rand</span>(<span style="color: #666666">1</span>, <span style="color: #666666">11</span>) <span style="color: #666666">.*</span> (<span style="color: #666666">2</span> <span style="color: #666666">.*</span> INIT_VAREPSILON) <span style="color: #666666">-</span> INIT_VAREPSILON;
</pre></div>


<p>$\varepsilon$ 应该选择小一点，这样神经网络的学习最有效率。一个经验做法是</p>
<p>$$<br />
\varepsilon^{(l)} = \frac{\sqrt{6}}{\sqrt{s_l} + \sqrt{s_{l+1}}}<br />
$$</p>
<p>$s_l, s_{l+1}$ 分别表示 $l$ 层和 $l+1$ 层的神经单元个数。即每层的参数范围根据这层的神经单元个数及下一层的神经单元个数。</p>
<h3 id="_29">总结</h3>
<p>使用神经网络解决问题时，需要经过两个步骤。一是设计神经网络的架构；二是训练出对应的神经网络参数。</p>
<h4 id="_30">神经网络架构</h4>
<p>在进行神经网络计算时，需要先进行神经网络的架构设计。架构设计时需要考虑以下三个事情：</p>
<ol>
<li>输入层的特征数量 number of input unit</li>
<li>输出层的单元个数 number of output unit，针对多类别的分类问题，可以把输出层设计成一个向量</li>
<li>隐藏层的个数以及每个隐藏层的单元数目。一般来讲，隐藏层的个数越多越好，但会增加计算的工作量。另外，多个隐藏层的单元数目一般是相同的。</li>
</ol>
<h4 id="_31">神经网络训练</h4>
<p>神经网络训练总共有六个步骤</p>
<ul>
<li>按照随机数对初始权重 (参数) 进行初始化</li>
<li>实现向前传播算法，以便针对任何的输入 $x^{(i)}$ 都能算出相应的 $h_\Theta(x^{(i)})$</li>
<li>实现神经网络成本函数 $J(\Theta)$ 来计算成本</li>
<li>实现向后传播算法，计算成本函数针对每个参数的偏微分 $\frac{\partial}{\partial \Theta_{ij}^{(l)}} J(\Theta)$<ul>
<li>需要遍历每个训练样本，即有个从 1 到 m 的循环</li>
<li>针对每个训练样本 $(x^{(i)}, y^{(i)})$ 执行向前传播算法和向后传播算法，以便算出 $l$ 层的激励 (Activations) $a^{(l)}$ 和误差 $\delta^{(l)}$</li>
<li>需要针对神经网络的每层算出*的值，这些层是 2, 3, &hellip; , L</li>
<li>最后，在循环外，算出成本函数的偏微分</li>
</ul>
</li>
<li>使用数值估计算法来验证神经网络成本函数的偏微分是否正确。验证通过后，关闭数值估计算法。</li>
<li>使用梯度下降或其他优化过的高级算法来对成本函数 $J(\Theta)$ 进行最小化运算</li>
</ul>
<h3 id="todo_3">TODO</h3>
<ol>
<li>使用 scipy 实现手写数字识别程序</li>
<li>从数学上证明 $g&rsquo;(z^{(L-1)}) = a^{(L-1)} .* (1 - a^{(L-1)})$</li>
<li>从数学上证明 $\frac{\partial}{\partial \Theta_{ij}^{(l)}} J(\Theta) = a_j^{(l)} \delta_i^{(l+1)}$</li>
<li>从数学上证明 $\frac{\partial}{\partial \Theta_{ij}^{(l)}} J(\Theta) = D_{ij}^{(l)}$</li>
<li>用向量化实现 Week 5 的练习，即向量化实现 forward propagation 和 back propagation。可以参考 <a href="http://deeplearning.stanford.edu/wiki/index.php/Neural_Network_Vectorization">Neural Network Vectorization</a>。</li>
</ol>
<h2 id="week-6">Week 6 机器学习应用的最佳实践以及系统设计</h2>
<h3 id="_32">机器学习算法的性能评估</h3>
<h4 id="_33">为什么需要评估机器学习算法的性能</h4>
<p>当我们辛苦开发出来的机器学习算法不能很好地预测新数据时，我们该怎么办呢？一般情况下，有以下几个方法：</p>
<ol>
<li>获取更多的训练数据</li>
<li>减少输入的特征数量，避免出现过拟合</li>
<li>增加有价值的特征，即重新解读并理解训练数据</li>
<li>增加多项式特征</li>
<li>减小正则化参数 lambda</li>
<li>增大正则化参数 lambda</li>
</ol>
<p>如何评估机器学习算法，以便遇到问题时能知道用上面方法中的哪个方法？</p>
<ol>
<li>对机器学习算法的性能进行评估，接下来就要介绍机器学习算法性能评估的方法</li>
<li>对机器学习算法进行诊断，诊断是指通过对机器学习算法进行测试，以便找出算法在哪种情况下能良好地工作，哪种情况下无法良好地工作。进而找出算法性能优化的方向和方法。</li>
</ol>
<h4 id="_34">预测函数模型性能评估</h4>
<p>怎么样判断我们的预测函数模型的性能是可以接受的呢？</p>
<p>我们可以把训练数据集分成两部分，随机选择 70% 的训练数据作为训练数据集，用来训练机器学习算法；另外 30% 作为测试数据集，用来验证训练出来的机器学习算法针对这些测试数据集的误差。一个好的机器学习算法应该是针对训练数据集成本函数比较低，即较准确地拟合数据，同时对测试数据集误差比较小，即对未知数据有良好的预测性。</p>
<p>如何计算测试数据集的误差呢？</p>
<p>简单地说，就是用测试数据集和训练出来的机器学习算法参数，代入相应的成本函数里计算测试数据集的成本。</p>
<p>针对线性回归算法，我们可以使用下面的公式计算测试数据集的误差，其中 m 是测试数据集的个数：<br />
$$<br />
J_{test}(\theta) = \frac{1}{2m} \sum_{i=0}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2<br />
$$</p>
<p>针对逻辑回归算法，可以使用下面的公式计算测试数据集的误差，其中 m 是测试数据集的个数：<br />
$$<br />
J_{test}(\theta) = -\frac{1}{m} \sum_{i=1}^m \left[ log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)})) \right]<br />
$$</p>
<p>针对分类问题时，还可以用分类错误率来代替成本函数算法，从而更直观地观察到一个算法对测试数据集的误差情况。我们定义错误率为</p>
<p>$$<br />
err(h_\theta(x), y) = \begin{cases}<br />
    1, &amp; \text{if error classification. $h_\theta(x) \geq 0.5$, $y$ = 0 or $h_\theta(x) &lt; 0.5$, $y$ = 1} \\<br />
    0, &amp; \text{if correct classification. $h_\theta(x) \geq 0.5$, $y$ = 1 or $h_\theta(x) &lt; 0.5$, $y$ = 0} \\<br />
\end{cases}<br />
$$</p>
<p>测试数据集的错误率定义为<br />
$$<br />
Test Error = \frac{1}{m} \sum_{i=0}^m err(h_\theta(x^{(i)}), y^{(i)})<br />
$$<br />
其中，m 为测试数据集的个数，$(x^{(i)}), y^{(i)})$ 为测试数据。</p>
<h4 id="_35">模型选择</h4>
<p>模型选择问题包括怎么样选择多项式来拟合数据？怎么样把数据集分成训练数据集，验证数据集，测试数据集，怎么样确定正则化参数 lambda 的值等等。</p>
<p>以多项式模型选择为例。假设我们用一阶多项式，二阶多项式，三阶多项式 &hellip; 十阶多项式来拟合数据，多项式的阶数我们记为 d。我们把数据集分成训练数据集和测试数据集。先用训练数据集训练出机器学习算法的参数 $\theta^{(1)}, \theta^{(2)}, \theta^{(3)}, &hellip; , \theta^{(10)}$ 分别代表从一阶到十阶多项式的参数。这个时候我们再用测试数据集算出针对测试数据集的成本 $J_test(\theta)$ 看哪个模型的测试数据集成本最低，这样我们选择这个测试数据集最低的多项式来拟合我们的数据。但实际上，<strong>这是不公平的，因为我们通过测试数据集的成本来选择多项式时，我们可能选择了一个针对测试数据集成本最低的多项式，即在模型选择过程中，我们通过测试数据集拟合了多项式的项数 d。</strong></p>
<p>为了解决这个问题，我们把数据分成三部分，随机选择 60% 的数据作为训练数据集，其成本记为 $J(\theta)$，随机选择剩下的 20% 数据作为交叉验证数据集 (Cross Validation)，其成本记为 $J_{cv}(\theta)$，剩下的 20% 作为测试数据集，其成本记为 $J_{test}(\theta)$。</p>
<p>在模型选择时，我们使用训练数据集来训练算法参数，用交叉验证数据集来验证参数，通过最小的交叉验证数据集的成本 $J_{cv}(\theta)$ 来选择合适的模型多项式 d ，最后再用测试数据集来测试选择出来的模型的针对测试数据集的错误率。<strong>因为在模型选择过程中，我们使用了交叉验证数据集，所以适配模型多项式 d 的过程中，实际上是没有使用我们的测试数据集的。这样保证了使用测试数据集来计算针对成本时，确保我们选择出来的模型没有见过测试数据，即测试数据集没有参与模型选择的过程。</strong>这样算出来的针对测试数据集的成本是相对公平合理的。</p>
<p>当然，在实践过程中，很多人直接把数据集分成训练数据集和测试数据集，然后通过比较测试数据集选择的成本来选择模型。</p>
<h4 id="bias-vs-variance">方差与偏差 Bias vs. Variance</h4>
<p>假定 $J_{train}(\theta)$ 表示训练误差；$J_{cv}(\theta)$ 表示交叉验证误差；那么高方差意味着 $J_{train}(\theta)$ 很大，$J_{cv}(\theta)$ 也很大。高偏差定义为 $J_{train}(\theta)$ 很小，但 $J_{cv}(\theta)$ 很大。</p>
<h4 id="_36">正则化与方差及偏差的关系</h4>
<p>当 lambda 为零时，容易产生过拟合，即 $J_{train}(\theta)$ 很小，但 $J_{cv}(\theta)$ 很大，这个就是高偏差的定义。而当 lambda 太大时，$J_{train}(\theta)$ 很大，$J_{cv}(\theta)$ 也很大，此时会产生高方差。</p>
<p>可以把数据集的成本作为纵坐标，lambda 作为横坐标，把 $J_{train}(\theta)$ 和 $J_{cv}(\theta)$ 以及 lambda 画在一个二维坐标轴上，这样我们可以明显地看到 $J_{train}(\theta)$ 和 $J_{cv}(\theta)$ 随着 lambda 的变化规则，从而编程自动找出最合适的 lambda 值。</p>
<h4 id="_37">学习曲线</h4>
<p>我们可以把 $J_{train}(\theta)$ 和 $J_{cv}(\theta)$ 作为纵坐标，画出与训练数据集 m 的大小的关系。</p>
<p>我们可以观察到当高偏差 (High Bias, Under Fitting) 时，随着训练数据集的增加，$J_{cv}(\theta)$ 不会明显地下降，且 $J_{train}(\theta)$ 增加很快，且最终<strong>$J_{train}(\theta)$ 和 $J_{cv}(\theta)$ 的值非常接近，且两个值都比较大</strong>。这个就是过拟合的表现。从这个关系也可以看出来，<strong>当发生高偏差时，过多的训练数据样例不会对算法性能有较大的改善</strong>。</p>
<p>当高方差产生时 (High Variance, Over Fitting)，比如我们用 100 阶的多项式来拟合数据。随着训练数据集 m 的增加，$J_{train}(\theta)$ 的增加比较缓慢，且值比较小。而 $J_{train}(\theta)$ 刚开始时很大，随着训练数据集 m 的增加，它会开始缓慢下降，但其值还是比较大。最终 <strong>$J_{train}(\theta)$ 和 $J_{cv}(\theta)$ 的值相差比较大。</strong>当发生高方差时，更多的训练数据样例会对算法性能有较大的改善，因为最终两条线会越来越接近，达到我们想要的效果**。</p>
<p>当需要改进学习算法时，可以画出学习曲线，以便判断算法是处在高偏差还是高方差问题。</p>
<h4 id="_38">决定下一步行动</h4>
<p>回到本周开始的地方，我们可以总结那些行动可以解决哪些算法问题。</p>
<ol>
<li>获取更多的训练数据 -&gt; 解决高方差问题 (High Variance, Over Fitting)</li>
<li>减少输入的特征数量，避免出现过拟合 -&gt; 解决高方差问题</li>
<li>增加有价值的特征，即重新解读并理解训练数据 -&gt; 解决高偏差问题 (High Bias, Under Fitting)</li>
<li>增加多项式特征 -&gt; 解决高偏差问题 (High Bias, Under Fitting)</li>
<li>减小正则化参数 lambda -&gt; 解决高偏差问题 (High Bias, Under Fitting)</li>
<li>增大正则化参数 lambda -&gt; 解决高方偏差问题 (High Variance, Over Fitting)</li>
</ol>
<p><strong>神经网络的过拟合</strong></p>
<p>针对神经网络时，我们可以设计两套方案。第一套方案是使用小型的神经网络，即只有一个隐藏层，隐藏层的神经单元个数也比较少。第二套是使用大型的神经网络，可以有多个隐藏层，每个隐藏层有多个神经单元。</p>
<p>一般来讲，方案一可能会导致高偏差，即欠拟合，但计算成本很低。而方案二可能会导致过拟合，且计算成本很高。针对欠拟合的情况，我们可以通过调整正则项参数 lambda 来解决。一般来讲，针对一个实际问题，选择一个大一点的神经网络，通过 lambda 纠正过拟合现象，这样的神经网络架构会比小型神经网络性能要好。</p>
<p>另外一个问题，多个隐藏层好还是一个隐藏层好呢？针对不同的实际问题结论是不一样的。一个通用的方法是在不同隐藏层个数的神经网络里进行比较，通过计算交叉验证数据集的成本 $J_{cv}(\theta)$ 来判断哪个网络更适合我们的实际问题。</p>
<h3 id="_39">机器学习系统设计</h3>
<h4 id="_40">构建垃圾邮件过滤系统</h4>
<p><strong>特征选择</strong></p>
<p>在实践中，可以遍历所有的训练数据集，即所有的垃圾邮件和所有的非垃圾邮件，找出各种出现频率最高的 10,000 - 50,000 个单词作为特征，假设特征数量记为 n。这样<strong>一封邮件就可以用一个 n 维向量来表示</strong>，即 n 个特征单词是否出现在邮件里，如果出现记为 1 不出现记为 0 。</p>
<p><strong>构建步骤</strong></p>
<ul>
<li>收集尽量多的数据，如 <a href="http://www.projecthoneypot.org">honeypot</a> 项目</li>
<li>从邮件路由信息中提取出有效的特征来区分垃圾邮件，路由信息放在邮件头部</li>
<li>从邮件的内容中提取复杂特征</li>
<li>开发一套算法来检查拼写错误。因为很多算法从邮件内容中通过关键字为特征来区分垃圾邮件，垃圾邮件系统为了跳过这个检查，故意把一些敏感词拼错，这样规避垃圾邮件检查机制</li>
</ul>
<p>至于哪个方法是最有效的，需要头脑风暴或者事先详细研究才能得出结论。当然，在算法通过检验之前，很难事先判断哪个特征是最有效的。</p>
<h4 id="_41">错误分析</h4>
<p>用机器学习算法解决问题时，可以偿试如下的策略</p>
<ul>
<li><strong>从简单的算法开始</strong>，先实现出来，然后使用交叉验证数据来验证结果。</li>
<li><strong>画出学习曲线</strong>，诊断算法的问题和优化方向，是需要去获取更多训练数据还是要增加特征等。</li>
<li>错误分析：<strong>针对交叉验证数据的错误项进行手动分析</strong>，试图从这些错误结果里找出更多线索和特征。</li>
</ul>
<p><strong>错误分析实例</strong></p>
<p>假设我们实现的垃圾邮件过滤算法，针对 500 封交叉验证数据里有 100 封被错误分类了，那么我们可以进行</p>
<ol>
<li>手动检查这些被错误分类的邮件类型，比如钓鱼邮件，卖药的邮件等等，通过手动分析总结出哪种类型的邮件被错误地分类数量最多，然后先把精力花在这种类型的邮件上面。</li>
<li>有哪些线索，特征有助于算法正确鉴别这些邮件。比如通过分析，我们发现异常路由的邮件数量有多少，错误拼写的邮件有多少，异常标点符号的邮件有多少。通过总结这些特征，决定我们应该要把时间花在哪方面来改善算法性能。</li>
</ol>
<p>比如，我们在实现垃圾邮件鉴别算法时，我们需要决定 Dicount/Discounts/Discounted/Discouting 等单词视为同一个单词还是不同的单词。如果要视为相同的单词，可以使用词干提取法 (Porter Stemmer) ，但使用词干提取法一样会带来问题，比如会错误地把 universe/university 归类为同一个单词。这个时候如何决策呢？</p>
<p>一个可行的办法是分别计算使用了词干提取法和不使用时候的 $J_{cv}(\theta)$ 和 $J_{test}(\theta)$ ，这样来判断到底是使用更好还是不使用性能更好。</p>
<p>实际上，优化算法过程中的很多偿试都可以使用这个方法来判断是否是有效的优化策略。</p>
<h4 id="_42">处理有倾向性的数据</h4>
<p>比如针对癌症筛查算法，根据统计，普通肿瘤中癌症的概率是 0.5% 。我们有个机器学习算法，在交叉验证数据时得出的准确率是 99.2%，错误率是 0.8% 。这个算法到底是好还是坏呢？如果努力改进算法，最终在交叉验证数据集上得出的准确率是 99.5%，错误率是 0.5% 到底算法性能是提高了还是降低了呢？</p>
<p>坦白讲，如果单纯从交叉验证数据集上测试准确率的方法很难进行判断到底算法是变好了还是变坏了。因为这个事情的先验概率太低了，假如我们写了一个超级简单的预测函数，总是返回 0，即总是认为不会得癌症，那么我们这个超级简单的预测函数在交叉验证数据集上得到的准确率是 99.5%，错误率是 0.5% 。因为总体而言，只有那 0.5% 真正得癌症的可怜虫被我们误判了。</p>
<p>那么我们怎么样来衡量分类问题的准确性能呢？我们引入了另外两个概念，<strong>查准率 (Precision)</strong> 和 <strong>召回率 (Recall)</strong>。还是以癌症筛查为例：</p>
<table>
<thead>
<tr>
<th>预测数据/实际数据</th>
<th>实际恶性肿瘤</th>
<th>实际良性肿瘤</th>
</tr>
</thead>
<tbody>
<tr>
<td>预测恶性肿瘤</td>
<td>True-Positive</td>
<td>False-Positive</td>
</tr>
<tr>
<td>预测良性肿瘤</td>
<td>False-Negative</td>
<td>True-Negative</td>
</tr>
</tbody>
</table>
<p>$$<br />
Precision = \frac{TruePosition}{TruePosition + FalsePositive}<br />
$$</p>
<p>$$<br />
Recall = \frac{TruePositive}{TruePositive + FalseNegative}<br />
$$</p>
<p>在处理先验概率低的问题时，我们总是把概率较低的事件定义为 1 ，并且总是把 $y=1$ 作为 Positive 的预测结果。有了这个公式，如果一个简单地返回 0 的预测函数，那么它的查准率和召回率都为 0。这显然不是个好的预测模型。</p>
<h4 id="_43">在查准率和召回率之间权衡</h4>
<p>假设我们想提高癌症的查准率，即只有在很有把握的情况下才预测为癌症。回忆我们在逻辑回归算法里，当 $h_\theta(x) &gt;= 0.5$ 时，我们就预测 $y = 1$ ，为了提高查准率，可以把门限值从 0.5 提高到 0.8 之类的。这样就提高了查准率，但这样会降低召回率。同样的道理，我们如果想提高如回率，可以降低门限值，从 0.5 降到 0.3 。这样召回率就会提高，但查准率就会降低。所以在实际问题时，可以要接实际问题，去判断是查准率重要还是召回率重要，根据重要性去调整门限值。</p>
<p><strong>如何评价算法的好坏</strong></p>
<p>由于我们现在有两个指标，查准率和如回率，如果有一个算法的查准率是 0.5, 召回率是 0.4；另外一个算法查准率是 0.02, 召回率是 1.0；那么两个算法到底哪个好呢？</p>
<p>为了解决这个问题，我们引入了 $F_1Score$ 的概念</p>
<p>$$<br />
F_1Score = 2 \frac{PR}{P + R}<br />
$$</p>
<p>其中 P 是查准率，R 是召回率。这样就可以用一个数值直接判断哪个算法性能更好。典型地，如果查准率或召回率有一个为 0，那么 $F_1Score$ 将会为 0。而理想的情况下，查准率和召回率都为 1 ，则算出来的 $F_1Score$ 为 1。这是最理想的情况。</p>
<p><strong>自动选择门限值</strong></p>
<p>前文介绍过，门限值可以调节查准率和召回率的高低。那么如何自动选择门限值以便让算法的性能最优呢？我们可以使用交叉验证数据，算出使 $F_1Score$ 最大的门限值。这个值就是我们自动选择出来的最优的门限值。</p>
<h4 id="_44">使用大量的数据集</h4>
<p>Michele Banko and Eric Brill 在 2011 年用四种算法进行了一个自然语言的机器学习训练，结果发现，数据量越大，训练出来的算法准确性越高。他们得出了下图的结论。</p>
<p><img alt="Accuracy and data size" src="http://img.ptcms.csdn.net/article/201506/18/55828e0dad1e5.jpg" /></p>
<p>然后这个结论是些前提：<strong>有足够的特征进行机器学习</strong>。怎么样判断是否有足够的特征呢？我们可以让这个领域的专家来人工预测。比如给出一个房子的面积，让房产经纪人预测其房价，他肯定无法正确地预测。因为特征不足。</p>
<p>怎么样从理论上证明这个结论呢？我们知道，如果我们有足够的特征来进行预测，意味着我们可以构建足够复杂的模型（比如神经网络）来让我们的预测函数有比较低的偏差 (Low Bais)，即让 $J_{train}(\theta)$ 的值很小。如果我们有足够多的数据，就可以确保我们可以训练出一个低方差 (Low Variance) 的算法，即我们可以让 $J_{cv}(\theta)$ 接近 $J_{train}(\theta)$ 。这样最终我们的测试数据成本值  $J_{test}(\theta)$ 也会靠近  $J_{train}(\theta)$ 。</p>
<h2 id="week-7-svm-support-vector-machine">Week 7 支持向量机算法 SVM (Support Vector Machine)</h2>
<p>支持向量机算法是工业和学术界都有广泛应用的强大的算法。</p>
<h3 id="_45">大间距分类算法</h3>
<p>支持向量机也称为大间距分类算法。大间距的意思是，用 SVM 算法计算出来的分界线会保留对类别最大的间距，即有足够的余量。</p>
<h4 id="_46">支持向量机算法的成本函数</h4>
<p>回顾之前的知识，逻辑回归算法的成本函数如下</p>
<p>$$<br />
J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)})) \right] + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2<br />
$$</p>
<p>从数学的角度，可以改写成下面的公式</p>
<p>$$<br />
J(\theta) = C \left[ \sum_{i=1}^m y^{(i)} cost_1(\theta^T x^{(i)}) + (1 - y^{(i)}) cost_0(\theta^T x^{(i)}) \right] + \frac{1}{2} \sum_{j=1}^n \theta_j^2<br />
$$</p>
<p>这就是用在支持向量机算法里的成本函数。</p>
<p>其中 $cost_1(\theta^T x^{(i)})$ 表示预测值为 1 的时候的成本的贡献；$cost_0(\theta^T x^{(i)})$ 表示预测值为 0 的时候对成本的贡献。</p>
<p>实际上 $cost_1(\theta^T x^{(i)})$ 是 $log(h_\theta(x^{(i)}))$ 的简化版。由于 $h_\theta(x)$ 是 Sigmoid Function。我们可以把 $log(\frac{1}{1 + e^{-z}})$ 函数在二维坐标上画出来，然后以 x 轴的 1 作为分界线，把函数曲线简化为两条直线构成的折线。当 $\theta^T x &lt;= 1$ 时，$cost_1(\theta^T x)$ 逐渐下降到 0 ，当 $\theta^T x &gt; 1$ 时，$cost_1(\theta^T x)$ 为 0。</p>
<p>使用可以相同的方法简化 $cost_0(\theta^T x)$。当 $\theta^T x &lt;= -1$ 时，$cost_0(\theta^T x)$ 为 0 ，当 $\theta^T x &gt; -1$ 时，$cost_0(\theta^T x)$ 是一条固定斜率的直线。</p>
<h4 id="_47">支持向量机的数学原理</h4>
<p><strong>向量内积的几何含义</strong></p>
<p>假设 u, v 是一个二维列向量，那么 $u^Tv$ 表示向量 v 在 向量 u 上的投影的长度。可以通过在二维平面上画出向量 u 和向量 v 来更清楚地看这个关系。</p>
<p>$$<br />
u^T v = u_1 v_1 + u_2 v_2 = p \|u\|<br />
$$</p>
<p>其中 p 就是 v 在 u 上的投影的长度；$\|u\|$ 是向量 u 的秩，即向量 u 的长度。</p>
<p><strong>从数学上理解为什么支持向量机会把类别边界的间距做到最大</strong></p>
<p>从成本函数的正则项 $\frac{1}{2} \sum_{j=1}^n \theta_j^2$ 在算法求解的过程中会试图让参数最小。按照数学上的理解，就是让参数的秩，即 $\|\theta\|$ 最小。</p>
<h3 id="_48">核</h3>
<h4 id="_49">核函数</h4>
<p>选择地标点 (landmark) $l^{(i)}$，针对给定的 $x$ ，使用相似性函数来定义新的特征：</p>
<p>$$<br />
\begin{align}<br />
f_i &amp;= similarity(x, l^{(i)}) \\<br />
&amp;= exp \left( - \frac{\| x - l^{(i)} \|^2}{2\sigma^2} \right) \\<br />
&amp;= exp \left( - \frac{\sum_{j=1}^n (x_j - l_j^{(i)})^2}{2\sigma^2} \right) \\<br />
\end{align}<br />
$$</p>
<p>针对新特征 $f_i$，我们的核函数 (高斯核函数) 为</p>
<p>$$<br />
kernel = \sum_{i=0}^n \theta_i f_i = \theta^T f<br />
$$</p>
<p>其中 $f_0 = 1$。则当 $kernel &gt;= 0$ 时，预测值为 1，当 $kernel &lt; 0$ 时，预测值为 0。</p>
<h4 id="_50">使用核函数来解决支持向量机算法</h4>
<p>定义地标点 (landmark) 的一个很自然的方法是直接把 landmark 定义在训练数据集的训练样例上，即 $l^{(i)}=x^{(i)}$。那么给定一个新的交叉验证数据集或测试数据集里的样例 $x$，它与 landmark 的相似性函数，即高斯核函数如下</p>
<p>$$<br />
f_i = similarity(x, l^{(i)}) = exp \left( - \frac{\| x - l^{(i)} \|^2}{2\sigma^2} \right)<br />
$$</p>
<p>针对训练样例，也满足上述核函数。由于我们选择 landmark 与训练样例重合，所以针对训练样例，$f_i=1$。</p>
<p><strong>计算预测值</strong></p>
<p>假如我们已经算出了 $\theta$，那么当 $\theta^Tf &gt;= 0$ 时，预测值为 1，反之为 0。</p>
<p><strong>计算参数</strong></p>
<p>根据 SVM 的成本函数，由于我们把 $f$ 代替 $x$ 作为新的特征，所以我们可以通过最小化下面的函数来计算得出参数 $\theta$</p>
<p>$$<br />
J(\theta) = C \left[ \sum_{i=1}^m y^{(i)} cost_1(\theta^T f^{(i)}) + (1 - y^{(i)}) cost_0(\theta^T f^{(i)}) \right] + \frac{1}{2} \sum_{j=1}^n \theta_j^2<br />
$$</p>
<p>针对上述公式，实际上 $m=n$，因为 $f$ 是由训练数据集 $x^{(i)}$ 定义，即 $f$ 是一个 m 维的向量。</p>
<p><strong>支持向量机算法的参数</strong></p>
<ol>
<li>C 值越大，越容易造成过拟合，即 lower bias, higher variance. 当 C 值越小，越容易造成欠拟合，即 higher bias, lower variance。</li>
<li>$\sigma^2$ 越大，高斯核函数的变化越平缓，会导致 higher bias, lower variance。当 $\sigma^2$ 越小，高斯核函数变化越快，会导致 lower bias, higher variance。</li>
</ol>
<h3 id="svm">实践中的 SVM</h3>
<p>一般情况下，我们使用 SVM 库 (liblinear, libsvm &hellip;) 来求解 SVM 算法的参数 $\theta$，而不是自己去实现 SVM 算法。在使用这些库的时候，我们要做的步骤如下</p>
<ul>
<li>选择参数 C</li>
<li>选择核函数<ul>
<li>可以支持空的核函数，即线性核函数 (linear kernel)。Predict &ldquo;y = 1&rdquo; if $\theta^Tx &gt;= 0$。</li>
<li>高斯核函数 $f_i = exp \left( - \frac{\| x - l^{(i)} \|^2}{2\sigma^2} \right)$，这个时候需要选择合适的参数 $\sigma^2$。</li>
</ul>
</li>
</ul>
<p>在使用第三方算法的时候，一般需要我们提供核函数的实现。输入参数是 $x_1, x_2$，输出为新的特征值 $f_i$。另外一个需要注意的点是，如果使用高斯核函数，在实现核函数时，需要对参数进行缩放，以便加快算法收敛速度。</p>
<p><strong>多类别的分类算法</strong></p>
<p>这个和逻辑回归里介绍的 one-vs.-all 一样。可以先针对一个类别和其他类别做二元分类，逐个分类出所有的类别。这样我们得到一组参数。假如，我们有 K 个类别，那么我们最终将得到 $\theta^{(1)}, \theta^{(2)}, \theta^{(3)} &hellip; \theta^{(K)}$ 个参数。</p>
<p><strong>算法选择</strong></p>
<p>逻辑回归和 SVM 都可以用来解决分类问题，他们适用的场景有些区别。</p>
<p>假设 n 是特征个数；m 是训练数据集的样例个数。一般可以按照下面的规则来选择算法。</p>
<p>如果 n 相对 m 来说比较大。比如 n = 10,000; m = 10 - 1000，如文本处理问题，这个时候使用逻辑回归或无核函数的 SVM 算法。<br />
如果 n 比较小，m 中等大小。比如 n = 1 - 1000; m = 10 - 10,000。那么可以使用高斯核函数的 SVM 算法。<br />
如果 n 比较小，m 比较大。比如 n = 1 - 1000; m = 50,000+ 。那么一般需要增加特征，并且使用逻辑回归或无核函数的 SVM 算法。</p>
<p>以上的所有情况都可以使用神经网络来解决。但训练神经网络的计算成本比较高。</p>
<h3 id="todo_4">TODO</h3>
<ul>
<li>使用神经网络重新实现 week 7 的垃圾邮件鉴别算法</li>
</ul>
<h2 id="week-8-unsupervised-learning">Week 8 无监督式学习 Unsupervised Learning</h2>
<h3 id="clustering">聚类问题 Clustering</h3>
<p>监督式学习时，输入数据分为 (x, y) ，目标是找出分类边界，即对新的数据进行分类。而无监督式学习只给出一组数据集 ${x_1, x_2, &hellip; , x_m}$ ，目标是去找出这组数据的模式特征，比如哪些数据是一种类型的，哪些数据是另外一种类型的。典型的无监督式学习包括市场细分，通过分析用户数据，来把一个产品的市场进行细分，找出细分人群。另外一个是社交网络分析，分析社交网络中的参与人员的不同特点，根据特点区分出不同群体。这些都是无监督式学习里的聚类 (clustering) 问题。</p>
<h4 id="k">K 均值算法</h4>
<p>K 均值算法包含两个步骤</p>
<ul>
<li>给聚类中心分配点：计算所有的训练样例，把他分配到距离某个聚类中心最短的的那聚类里。</li>
<li>移动聚类中心：新的聚类中心移动到这个聚类所有的点的平均值处。</li>
</ul>
<p>一直重复做上面的动作，直到聚类中心不再移动为止。这个时候我们就探索出了数据集的结构了。</p>
<p>用数学的方法来描述 K 均值算法如下：</p>
<p>算法有两个输入信息。一是 K 表示选取的聚类个数；二是训练数据集 ${x^{(1)}, x^{(2)}, &hellip; , x^{(m)}}$。</p>
<ol>
<li>随机选择 K 个聚类中心 $u_1, u_2, &hellip; , u_k$。</li>
<li>从 1 - m 遍历所有的数据集，计算 $x^{(i)}$ 分别到 $u_1, u_2, &hellip; , u_k$ 的距离，记录距离最短的聚类中心点。然后把 $x^{(i)}$ 这个点分配给这个聚类。令 $c^{(i)} = j$ 其中 $u_j$ 就是与 $x^{(i)}$ 距离最短的聚类中心点。计算距离时，一般使用 $\| x^{(i)} - u_j \|^2$ 来计算。</li>
<li>从 1 - K 遍历所有的聚类中心，移动聚类中心的新位置到这个聚类的均值处。即 $u_j = \frac{1}{c} \left( \sum_{d=1}^c \right)$ ，其中 c 表示分配给这个聚类的训练样例点的个数。如果特殊情况下，没有点分配给这个聚类中心，那么说明这个聚类中心就不应该存在，直接删除掉这个聚类中心，最后聚类的个数变成 K - 1 个。</li>
<li>重复步骤 2 ，直到聚类中心不再移动为止。</li>
</ol>
<h4 id="k_1">K 均值算法成本函数</h4>
<p>$$<br />
J = \frac{1}{m} \sum_{i=1}^m \| x^{(i)} - u_{c^{(i)}} \|^2<br />
$$</p>
<p>其中， $c^{(i)}$ 是训练样例 $x^{(i)}$ 分配的聚类序号；$u_{c^{(i)}}$ 是 $x^{(i)}$ 所属的聚类的中心点。</p>
<h4 id="_51">随机初始化聚类中心点</h4>
<p>假设 K 是聚类的个数，m 是训练样本的个数，那么必定有 $K &lt; m$。在随机初始化时，随机从 m 个训练数据集里选择 K 个样本来作为聚类中心点。这是正式推荐的随机初始化聚类中心的做法。</p>
<p>在实际解决问题时，最终的聚类结果会和随机初始化的聚类中心点有关。即不同的随机初始化的聚类中心点可能得到不同的最终聚类结果。因为成本函数可能会收敛在一个局部最优解，而不是全局最优解上。一个解决方法是多做几次随机初始化的动作，然后训练出不同的取类中心点以及聚类节点分配方案。然后用这些值算出成本函数，最终选择那个成本最小的。</p>
<p>比如，假设我们做 100 次运算，步骤如下：</p>
<ol>
<li>随机选择 K 个聚类中心点</li>
<li>运行 K 均值算法，算出 $c^{(1)}, c^{(2)}, &hellip; , c^{(m)}$ 和 $u_1, u_2, &hellip; , u_k$</li>
<li>使用 $c^{(1)}, c^{(2)}, &hellip; , c^{(m)}$ 和 $u_1, u_2, &hellip; , u_k$ 算出最终的成本值</li>
<li>记录最小的成本值，然后跳回步骤 1，直到达到最大运算次数</li>
</ol>
<p>这样我们可以适当加大运算次数，从而求出全局最优解。</p>
<h4 id="_52">选择聚类的个数</h4>
<p>怎么样选择合适的聚类个数呢？实际上聚类个数和业务有紧密的关联，比如我们要对 T-Shirt 大小进行聚类分析，我们是分成 3 个尺寸好呢还是分成 5 个尺寸好？这个更多的是个业务问题而非技术问题。3 个尺寸可以给生产和销售带来便利，但客户体验可能不好。5 个尺寸客户体验好了，但可能会给生产和库存造成不便。</p>
<p>从技术角度来讲，也是有一些方法可以来做一些判断的。我们可以把聚类个数作为横坐标，成本函数作为纵坐标，这样把成本和聚类个数的数据画出来。大体的趋势是随着 K 值越来越大，成本越来越低。我们找出一个拐点，即在这个拐点之前成本下降比较快，在这个拐点之后，成本下降比较慢，那么很可能这个拐点所在的 K 值就是我们要寻求的最优解。</p>
<h3 id="dimensionality-reduction">维数约减 Dimensionality Reduction</h3>
<h4 id="_53">动机</h4>
<p><strong>动机一：数据压缩</strong></p>
<p>维数约减即减少数据的维度，比如从 2 维降成 1 维，从 3 维降成 2 维等。好处是节省内存，提高运算速度。比如，我们有多个特征，其中两个特征的相关性非常大，一个是用 cm 测量的长度，另外一个是用 inch 测量的长度 (实际上这可能是个真实的例子，因为一个实际问题可能有 1000 个特征，而采集这些特征的工程师可能不是同一个人，这样他们采集回来的数据就可能存在重复，即高相关性)。那么我们可以把这两个高相关性的特征用一条直线来表示，$x^{(i)} = {x_1^{(i)}, x_2^{(i)}}$ 简化为 $z^{(i)} = {z_1^{(i)}}$。相同的原理，如果在一个 3 维空间里，一些点基本分布在一个平面上，那么就可以把 3 维降成 2 维，即 $x^{(i)} = {x_1^{(i)}, x_2^{(i)}, x_3^{(i)}}$ 简化为 $z^{(i)} = {z_1^{(i)}, z_2^{(i)}}$。</p>
<p><strong>动机二：数据可视化</strong></p>
<p>比如考查一个国家的经济状况，可能会有 50 个特征，经济总量，人均 GDP，出口值，进口值等等。如果想要直观地观察多个国家之间的关系，就比较难办。因为我们很难画出 50 个特征的图出来。这个时候，我们可以把 50 个特征简化为 2 维或 3 维的数据，然后画出 2D 或 3D 图出来，就可以直观地观察这些数据的样子。</p>
<h4 id="principal-component-analysis-pca">主成份分析法 Principal Component Analysis (PCA)</h4>
<p>这是目前最常用和流行的数据降维方法。</p>
<p><strong>PCA 公式</strong></p>
<p>假设需要把 2 维数据降为 1 维数据时，我们需要找出一个向量 $u^{(1)}$ ，以便让 2 维数据的点在这个向量所在的直线上的投射误差最小。</p>
<p>假如需要把 3 维数据降为 2 维数据时，我们需要找出两个向量 $u^{(1)}, u^{(2)}$，以便让 3 维数据的点在这两个向量所决定的平面上的投射误差最小。</p>
<p>从数学角度更一般地描述主成份分析法。当我们需要从 n 维数据降为 k 维数据时，我们需要找出 k 个向量 $u^{(1)}, u^{(2)}, &hellip; , u^{(k)}$ ，把 n 维的数据投射到这 k 个向量决定的线性空间里，最终使<strong>投射误差</strong>最小化的过程。</p>
<p><strong>PCA 算法</strong></p>
<p>在进行 PCA 算法前，需要对数据进行预处理。预处理包括两个步骤：</p>
<ul>
<li>数据归一化 Mean Normalization：使数据的均值为零。加快 PCA 运算速度。</li>
<li>数据绽放 Feature Scaling：使不同的特征数值在同一个数量级。</li>
</ul>
<p>数据归一化公式为：</p>
<p>$$<br />
z_j^{(i)} = x_j^{(i)} - \mu_j<br />
$$</p>
<p>其中，$\mu_j$ 是训练样本中第 j 个特征 ($x_j^{(i)}$) 的平均值的平均值。然后用 $z_j^{(i)}$ 代替 $x_j^{(i)}$ 进行 PCA 运算。</p>
<p>接着对数据进行缩放 (Feature Scaling)。缩放只在不同特征数据不在同一个数量级上时才使用。</p>
<p>$$<br />
x_j^{(i)} = \frac{x_j^{(i)} - \mu_j}{s_j}<br />
$$</p>
<p>其中，$\mu_j$ 是训练样本中第 j 个特征 ($x_j^{(i)}$) 的平均值的平均值，即 $\mu_j = \frac{1}{m} \sum_{i=1}^m x_j^{(i)}$， $s_j$ 是训练样本中第 j 个特征 ($x_j^{(i)}$) 的范围，即 $s_j = max(x_j^{(i)}) - min(x_j^{(i)})$。</p>
<p>数据预处理完，我们需要计算<strong>协方差矩阵 (Covariance Matrix)</strong>，用大写的 Sigma 表示：</p>
<p>$$<br />
\Sigma = \frac{1}{m} \sum_{i=1}^m (x^{(i)}) (x^{(i)})^T<br />
$$</p>
<p>如果把训练样例用行向量来表示，那么 X 将是一个 m x n 的矩阵。向量化计算 Sigma 的公式将是：</p>
<p>$$<br />
\Sigma = \frac{1}{m} X^T X<br />
$$</p>
<p>计算结果 Sigma 将是一个 n x n 矩阵。接着，计算协方差矩阵的<strong>特征向量 (eigenvectors)</strong>：</p>
<p>$$<br />
[U, S, V] = svd(Sigma)<br />
$$</p>
<p><code>svd</code> 是奇异值分解 (Singular Value Decomposition)，是高级线性代数的内容。在 Octave 里，也可以使用 <code>eig</code> 函数来求解协方差矩阵的特征向量。这里，Sigma 是 n x n 矩阵，经过 <code>svd</code> 运算后，我们真正关心的是 U。它是一个 n x n 矩阵。如果我们选择 U 的列作为向量，那么我们得到 n 个列向量 $u^{(1)}, u^{(2)}, &hellip; , u^{(n)}$，我们如果需要把数据降维为 k 维，那么我们只需要选取前 k 个向量即可，即 $u^{(1)}, u^{(2)}, &hellip; , u^{(k)}$。</p>
<p>接着，我们计算降维后的值 z，假设降维前的值为 $x^{(i)}$，降维后为 $z^{(i)}$，那么：</p>
<p>$$<br />
z^{(i)} = U_{reduce}^T x^{(i)}<br />
$$</p>
<p>其中，$U_{reduce} = [u^{(1)} u^{(2)} &hellip; u^{(k)}]$。看一下数据维度，$U_{reduce}$ 是 n x k 矩阵，$x^{(i)}$ 是 n x 1 矩阵，$z^{(i)}$ 是 k x 1 矩阵。</p>
<p>实现时可以用向量化来提高性能。假设 X 是 m x n 矩阵，m 表示训练样例个数，n 表示特征数。用大写的 Z 表示降维后的数据，是一个 m x k 的矩阵。$U_{reduce}$ 是 n x k 的主成份特征矩阵，每列表示一个主成份特征。那么他们满足下面的关系：</p>
<p>$$<br />
Z = X * U_{reduce}<br />
$$</p>
<p>要从数学上证明这样计算出来的 $z^{(i)}$ 就是 $x^{(i)}$ 在 $U_{reduce}$ 线性空间投射，使得其投射误差最小，将是一个非常复杂的过程。所幸如果我们单纯从应用 PCA 算法来对数据进行降维的角度来看的话，借用 Octave/Matlab 等现成函数，计算过程相对比较简单。</p>
<h4 id="pca">PCA 应用</h4>
<p><strong>数据还原</strong></p>
<p>我们怎么样从压缩过的数据里还原出压缩前的数据呢？从前文的计算公式，我们知道降维后的数据计算公式 $z^{(i)} = U_{reduce}^T x^{(i)}$。所以，如果要还原数据，我们可以使用下面的公式：</p>
<p>$$<br />
x_{approx}^{(i)} = U_{reduce} z^{(i)}<br />
$$</p>
<p>其中，$U_{reduce}$ 是 n x k 维矩阵，$z^{(i)}$ 是 k x 1 列向量。这样算出来的 $x^{(i)}$ 就是 n x 1 列向量。</p>
<p>向量化运算公式为：</p>
<p>$$<br />
X_{approx} = Z * U_{reduce}^T<br />
$$</p>
<p>其中 $X_{approx}$ 是还原回来的数据，是个 m x n 矩阵，每行表示一个训练样例。Z 是个 m x k 矩阵，是压缩后的数据。$U_{reduce}$ 是 n x k 的主成份特征矩阵，每列表示一个主成份特征。</p>
<p><strong>PCA 算法中 K 参数的选择</strong></p>
<p>怎么样选择参数 K 呢？K 是主成份分析法中主成份的个数。可以用下面的公式来判断选择的 K 是否合适：</p>
<p>$$<br />
\frac{ \frac{1}{m} \sum_{i-1}^m \| x^{(i)} - x_{approx}^{(i)} \|^2 }{ \frac{1}{m} \sum_{i=1}^m \|  x^{(i)} \| } \le 0.01<br />
$$</p>
<p>其中分子部分表示平均投射误差的平方；分母部分表示所有训练样例到原点的距离的平均值。这里的物理意义用术语可以描述为 <strong>99% 的数据真实性被保留下来了 (99% of variance is retianed)</strong>。简单地理解为压缩后的数据还原出原数据的的准确度为 99%。另外常用的比率还有 0.05 ，这个时候准确度就是 95%。在实际应用中，可以根据要解决的问题的场景来决定这个比率。</p>
<p>假设我们的还原率要求是 99%，那么用下面的算法来选择参数 K：</p>
<ol>
<li>让 K = 1</li>
<li>运行 PCA 算法，计算出 $U_{reduce}, z^{(1)}, z^{(2)}, &hellip; , z^{(m)}, x_{approx}^{(1)}, x_{approx}^{(2)}, &hellip; , x_{approx}^{(m)}$</li>
<li>利用 $\frac{ \frac{1}{m} \sum_{i-1}^m \| x^{(i)} - x_{approx}^{(i)} \|^2 }{ \frac{1}{m} \sum_{i=1}^m \|  x^{(i)} \| }$ 计算投射误差率，并判断是否满足要求，如果不满足要求，K = K + 1，继续步骤 2；如果满足要求，K 即是我们选择的参数</li>
</ol>
<p>这个算法容易理解，但实际上效率非常低下，因为每做一次循环都需要运行一遍 PCA 算法。另外一个更高效的方法是利用 <code>svd</code> 函数返回的 S 矩阵：$[U, S, V] = svd(Sigma)$。其中 S 是个 n x n 对角矩阵，即只有对角线上的值非零其他元素均为零。</p>
<p>从数学上可以证明（从应用角度，可以忽略这个证明过程），投射误差率也可以使用下面的公式计算：</p>
<p>$$<br />
1 - \frac{\sum_{i=1}^k S_{ii}}{\sum_{i=1}^n S_{ii}}<br />
$$</p>
<p>这样运算效率大大提高，我们只需要调用一次 <code>svd</code> 函数即可。</p>
<p><strong>PCA 应用</strong></p>
<p>PCA 的一个典型应用是用来<strong>加快监督学习 (Supervised Learning) 的速度</strong>。</p>
<p>比如，我们有 m 个训练数据 $(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), &hellip; , (x^{(m)}, y^{(m)})$，其中 $x^{(1)}$ 是 10,000 维的数据，想像一下，如果这是个图片分类问题，如果输入的图片是 100 x 100 分辨率的。那么我们就有 10,000 维的输入数据。</p>
<p>使用 PCA 来加快算法运算速度时，我们把输入数据分解出来 $x^{(1)}, x^{(2)}, &hellip; , x^{(m)}$，然后运用 PCA 算法对输入数据进行降维压缩，得到降维后的数据 $z^{(1)}, z^{(2)}, &hellip; , z^{(m)}$，最后得到新的训练样例 $(z^{(1)}, y^{(1)}), (z^{(2)}, y^{(2)}), &hellip; , (z^{(m)}, y^{(m)})$。利用新的训练样例训练出关于压缩后的变量 $z$ 的预测函数 $h_theta(z)$。</p>
<p>需要注意，PCA 算法只用来处理训练样例，运行 PCA 算法得到的转换参数 $U_{reduce}$ 可以用来对交叉验证数据集 $x_{cv}^{(i)}$ 以及测试数据集 $x_{test}^{(i)}$ 进行转换。当然，还需要相应地对数据进行归一化处理或对数据进行缩放。</p>
<p><strong>PCA 误用</strong></p>
<p>PCA 的典型应用场景是对数据进行压缩，减少磁盘/内存占用，加快算法运行速度。另外一个是用来数据可视化 (降到 2 维或 3 维)。我们了解到 PCA 可以对数据进行降维，即减少特征数，有人用 PCA 来解决<strong>过拟合</strong>问题。这可能在某些情况下会起作用，但实际上 <strong>PCA 不是一个好的解决过拟合的方法</strong>。解决过拟合应该使用正则化，加大成本函数里正则项的比重。</p>
<p><strong>PCA 滥用</strong></p>
<p>另外一个场景是在设计机器学习算法时，一开始就引入 PCA 来对数据进行压缩降维。实际上这不是好的方法。我们应该尽量使用原始数据来进行机器学习运算，当出现问题时，比如内存占用太大，运算时间太长等问题时，我们才考虑用 PCA 来优化。PCA 是算法优化的一个步骤，而不是机器学习系统里的必须步骤。</p>
<h2 id="week-9">Week 9 异常检测和推荐系统</h2>
<h3 id="_54">异常检测</h3>
<h4 id="_55">异常检测模型和实例</h4>
<p>给定一组数据 $x^{(1)}, x^{(2)}, &hellip; , x^{(m)}$，我们建立一个模型 $p(x)$，当有一个新的实例 $x_{test}$ 时，如果 $p(x_{test}) \le \epsilon$ 我们就认为 $x_{test}$ 是异常的。</p>
<p>异常检测在网站防盗等领域有广泛的应用，比如我们可以提取用户的一些特征，$x_1$ 代表用户的登录次数，$x_2$ 表示用户游览的页面个数，$x_3$ 表示用户的打字速度，$x_4$ 表示用户的交易次数等等，建立完特征，根据用户的历史数据建立一个模型，当某次用户的行为偏离这个模型较远时，可能这个用户的帐户就是被盗了。</p>
<p>另外一个应用领域是在工业制造。比如某个制造飞机引擎的公司，从飞机引擎提取出一系列的特征值，并且训练出一个模型。当新制造出来的引擎符合这个模型时，就可认为是良品，如果偏离这个模型较远时，就可以认为可能有缺陷，需要进一步的检测。</p>
<p>异常检测还在数据中心有广泛的应用，比如可以从一台服务器上提取出一系列特征，如内存占用，CPU 使用率，网络吞吐量，磁盘访问频率等等。利用这些特征建立一个模型。当某个服务器偏离这个模型较远时，可能这台机器快要死机了，就可以进一步查看这台机器的情况以便做出相应的处理。</p>
<h4 id="_56">高斯分布</h4>
<p>高斯分布也称为正太分布。高斯分布有两个参数，一个是平均值 $\mu$，另外一个是方差 $\sigma^2$ ($\sigma$ 称为标准差)，给定一个数值 X 作为横轴，它出现在不同位置的概率作为 Y 轴，在二维坐标上画出的图形是一个“钟形”的图形。用数据公式给出高斯分布的公式如下：</p>
<p>$$<br />
p(x; \mu, \sigma^2) = \frac{1}{\sigma \sqrt{2\pi}} exp \left( - \frac{(x - \mu)^2}{2 \sigma^2} \right)<br />
$$</p>
<p><strong>几个例子</strong></p>
<p>可以用不同的 $\mu, \sigma$ 的值画出高斯分布的图形，观察不同的参数对高斯分布中概率密度和影响。</p>
<ol>
<li>$\mu = 0, \sigma = 1$ 时的图形</li>
<li>$\mu = 0, \sigma = 0.5$ 时的图形</li>
<li>$\mu = 0, \sigma = 2$ 时的图形</li>
<li>$\mu = 3, \sigma = 0.5$ 时的图形</li>
</ol>
<p><strong>参数估计</strong></p>
<p>假设我们有一个数据集 $x^{(1)}, x^{(2)}, &hellip; , x^{(m)}$，其中 $x^{(i)} \in R$。且 $x^{(i)}$ 满足高斯分布，记作 $x^{(i)} \sim N(\mu, \sigma^2)$，如何算出高斯分布的参数 $\mu, \sigma^2$ 呢？</p>
<p>算法可以用下面的公式给出：</p>
<p>$$<br />
\mu = \frac{1}{m} \sum_{i=1}^m x^{(i)}<br />
$$</p>
<p>$$<br />
\sigma^2 = \frac{1}{m} \sum_{i=1}^m (x^{(i)} - \mu)^2<br />
$$</p>
<p>这个实际上就是概率论里的极大似然法来估计参数。另外需要提一点，计算方差 $\sigma^2$ 的公式里，一些概率论书本里分母是用 $m-1$，但机器学习领域喜欢直接用 $m$ ，虽然这是两个不同版本的公式，但在实际应用中，如果样例个数足够多，即 m 很大的话，实际计算结果差别不大。</p>
<h4 id="_57">异常检测算法</h4>
<p>假设我们有一个数据集 $x^{(1)}, x^{(2)}, &hellip; , x^{(m)}$，其中 $x^{(i)} \in R^n$，其中每个特征都独立地满足高斯分布，即 $x_j^{(i)} \sim N(\mu_j, \sigma_j^2)$。那么高斯分布的概率密度函数为：</p>
<p>$$<br />
p(x) = \prod_{j=1}^n p(x_j; \mu_j, \sigma_j^2)<br />
$$</p>
<p>其中 $\prod$ 是连乘符号，表示其后的式子相乘。</p>
<p>利用高斯分布进行异常检测的算法可以完整地描述如下：</p>
<ul>
<li>特征选择。选择那些能鉴别出异常的特征 $x_j$。</li>
<li>针对每个特征，计算出其高斯分布参数 $\mu_j, \sigma_j^2$。计算公式为:</li>
</ul>
<p>$$<br />
\mu_j = \frac{1}{m} \sum_{i=1}^m x_j^{(i)}<br />
$$</p>
<p>$$<br />
\sigma_j^2 = \frac{1}{m} \sum_{i=1}^m (x_j^{(i)} - \mu_j)^2<br />
$$</p>
<ul>
<li>给定一个新的实例 $x$，计算其出现的概率 $p(x)$。计算公式为：</li>
</ul>
<p>$$<br />
p(x) = \prod_{j=1}^n p(x_j; \mu_j, \sigma_j^2) = \prod_{j=1}^n \frac{1}{\sigma_j \sqrt{2\pi}} exp \left( - \frac{(x_j - \mu_j)^2}{2 \sigma_j^2} \right)<br />
$$</p>
<ul>
<li>选定一个较小的常数 $\epsilon$，如果 $p(x) \le \epsilon$ 则表示新的实例 $x$ 是异常的。</li>
</ul>
<p><strong>TODO</strong></p>
<p>假设 $X \in R^{m \times n}$，其中 m 是训练样例个数，n 是特征数。使用向量化公式计算多元高斯分布的 octave 代码如下：</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">p = (<span style="color: #666666">2</span> <span style="color: #666666">*</span> <span style="color: #AA22FF">pi</span>) ^ (<span style="color: #666666">-</span> n <span style="color: #666666">/</span> <span style="color: #666666">2</span>) <span style="color: #666666">*</span> det(Sigma2) ^ (<span style="color: #666666">-0.5</span>) <span style="color: #666666">*</span> <span style="color: #AA22FF">exp</span>(<span style="color: #666666">-0.5</span> <span style="color: #666666">*</span> sum(<span style="color: #AA22FF">bsxfun</span>(@times, X <span style="color: #666666">*</span> pinv(Sigma2), X), <span style="color: #666666">2</span>));
</pre></div>


<p>怎么样推导出这个公式呢？</p>
<h4 id="_58">异常检测算法的性能评价</h4>
<p>怎么样评价一个异常检测算法的性能是否达到要求呢？</p>
<p>假设我们拿飞机引擎制造作为例子，我们有 10,000 个正常的引擎数据，20 个异常的引擎数据。这样我们把数据分成三份：</p>
<ul>
<li>训练数据集：6,000 个正常的引擎数据</li>
<li>交叉验证数据集：2,000 个正常的引擎数据；10 个异常引擎数据</li>
<li>测试数据集：2,000 个正常的引擎数据；10 个异常的引擎数据</li>
</ul>
<p>接下来我们开始来评估算法的性能</p>
<ul>
<li>使用训练数据集来建立 $p(x)$ 模型</li>
<li>使用下面的模型来预测交叉验证数据集和测试数据集里的样例</li>
</ul>
<p>$$<br />
y = \begin{cases}<br />
    1, &amp; if p(x) &lt; \epsilon (anormaly)\\<br />
    0, &amp; if p(x) \ge \epsilon (normal) \\<br />
\end{cases}<br />
$$</p>
<ul>
<li>使用交叉验证数据集来计算<strong>查准率</strong>，<strong>召回率</strong>以及<strong>$F_1Score$</strong></li>
</ul>
<p>$$<br />
Precision = \frac{TruePositive}{TruePositive + FalsePositive}<br />
$$</p>
<p>$$<br />
Recall = \frac{TruePositive}{TruePositive + FalseNegative}<br />
$$</p>
<p>$$<br />
F_1Score = 2 \frac{PR}{P + R}<br />
$$</p>
<ul>
<li>使用交叉验证数据集来选择合适的 $\epsilon$，来让 $F_1Score$ 的值最大</li>
<li>最后使用测试数据集来计算模型的最终性能 $F_1Score$</li>
</ul>
<p>TruePosition: 真阳性，即真实结果是真，算法的预测结果也是真<br />
FalsePositive: 假阳性，即真实结果是假，算法的预测结果是真<br />
FalseNegative: 假阴性，即真实结果是真，算法的预测结果是假</p>
<h4 id="_59">异常检测与监督学习的区别</h4>
<p>上一节介绍的飞机引擎异常检测算法里，我们有正常的数据，有异常的数据，为什么不直接用逻辑回归或神经网络算法来对一个新引擎进行直接预测呢？实际上异常检测和监督学习有其不同的适用范围。</p>
<p><strong>异常检测适用范围</strong></p>
<ul>
<li>正向样本 (y = 1) 非常少 (0 - 20)，但负向样本 (y = 0) 很多</li>
<li>有太多的异常类型，算法很难从正常的数据样例里学习到异常的特征</li>
<li>未来新出来的异常数据和我们训练样例里现有的异常数据根本不一样，即没见过的异常样例</li>
</ul>
<p>如果满足这三个条件中的任何一个，都需要考虑使用异常检测算法，而不是监督学习相关的算法。监督学习算法适用于有大量的正向样本，也有大量的负向样本，有足够的正向样本让算法来学习其特征，未来新出现的正向数据可能和训练样例里的某个正向样本类似。</p>
<p>由此可见异常检测和监督学习相关算法的适用范围是不一样的。下面是一些例子</p>
<table>
<thead>
<tr>
<th>异常检测</th>
<th>监督学习</th>
</tr>
</thead>
<tbody>
<tr>
<td>信用卡诈骗</td>
<td>垃圾邮件识别</td>
</tr>
<tr>
<td>制造业异常产品检测</td>
<td>天气预报 (晴/雨 等)</td>
</tr>
<tr>
<td>数据中心机器异常检测</td>
<td>癌症检测</td>
</tr>
</tbody>
</table>
<h4 id="_60">异常检测中的特征选择</h4>
<p><strong>非高斯分布特征的转换</strong></p>
<p>使用高斯分布来作为异常检测模型时，有个前提，即每个特征都需要独立地呈现高斯分布。如果我们获得的特征数据可视化后发现他不是一个高斯分布的钟形图形怎么办呢？我们可以用 octave 的 <code>hist</code> 命令来画出特征的柱状图，然后对特征进行转换，比如画出 $log(x)$ 的图形，或画出 $x^{0.5}$ 或 $x^{0.1}$ 的柱状图。看图形的形状来判断是否符合高斯分布。然后选择转换后的特征来加入我们的异常检测算法中来。</p>
<p><strong>异常检测的错误分析</strong></p>
<p>假如我们有一个异常检测算法，算出正常样本的概率很大，但算出异常样本的概率也很大。这样就没有办法区分出异常样本了。这个时候，一个可行的方法是去查看这个概率很大的异常样本，看能不能得到一些启发，以便让我们发现一些新的特征，用这个特征可以把这种异常样本区分出来。</p>
<p><strong>特征选择的一般性原则</strong></p>
<p>选择那些在异常时，特征值会变得很大或很小的特征来作为异常检测的特征。比如，我们要检测数据中心中的计算机工作是否正常，我们有下面几个特征：</p>
<ul>
<li>CPU 使用率</li>
<li>网络吞吐量</li>
<li>磁盘访问速度</li>
<li>内存使用情况</li>
</ul>
<p>一般情况下，CPU 使用率和网络吞量是成正比的，即用户访问越多，CPU 使用率就越高。当 CPU 使用率很高，但网络吞吐量比较小时，这个时候这个机器可能就出现异常了，比如进入了死循环了。如果我们想检测出这种异常，可以选择 <em>CPU 使用率</em> / <em>网络吞吐量</em> 来作为一个新的特征，加入我们的异常检测算法里。</p>
<h4 id="_61">多元高斯分布</h4>
<p><strong>为什么需要多元高斯分布？</strong></p>
<p>我们拿数据中心的电脑异常检测来当例子，我们一个指标是内存占用，另外一个指标是 CPU 使用率。我们使用数据可视化观察到，内存占用和 CPU 使用率大概呈线性关系，即所有的训练样例分布在一个长椭圆形里。这个时候，如果有个新的数据，内存占用很高，但 CPU 使用率不高，出现在椭圆的外面。按道理，这个样例应该被判定为异常，但实际上，我们上面介绍的算法会把这个样例当成正常的，因为它没有意识到内存占用和 CPU 使用率呈线性关系这样的事实。</p>
<p><strong>多元高斯分布公式</strong></p>
<p>假设训练样例 $x \in R^n$，我们这次不逐个变量建模，而是把 $x$ 当成一个列向量，整体进行建模。这个时候也有两个参数，一个是 $\mu \in R^n$，另外一个是 $\Sigma \in R^{n \times n}$，这里，$\Sigma$ 和我们 PCA 算法里的 $\Sigma$ 一样，称为协方差矩阵 (Covariance Matrix)。</p>
<p>$$<br />
p(x; \mu, \Sigma) = \frac{1}{(2 \pi)^{n/2} |\Sigma|^{1/2}} exp \left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right)<br />
$$</p>
<p>这就是多元高斯分布的公式。其中 $|\Sigma|$ 是矩阵的行列式，在 Octave 里使用 <code>det</code> 函数来计算。</p>
<p><strong>怎么样理解多元高斯分布能解决本节开头提出的问题呢？</strong></p>
<p>答案是我们可以通过调整协方差矩阵来拟合两个特征的线性关系。假设我们有两个特征 $x_1, x_2$，一个直观的方法来观察这个效果，是在 3D 环境下画出多元高斯分布图及其等高线图。这样就可以直观地看到多元高斯分布如何拟合 $x_1, x_2$ 之间的线性关系的。</p>
<p>具体来讲，给出多元高斯分布的初始参数：</p>
<p>$$<br />
\mu =<br />
\begin{bmatrix}<br />
0 \\<br />
0 \\<br />
\end{bmatrix}<br />
$$</p>
<p>$$<br />
\Sigma =<br />
\begin{bmatrix}<br />
1 &amp; 0 \\<br />
0 &amp; 1 \\<br />
\end{bmatrix}<br />
$$</p>
<p>试着去不断地改变 $\Sigma$ 的值，在 3D 环境下画出这些图形，即可直接地观察到多元高斯分布怎么样通过调整协方差矩阵来拟合特征的正相关或负相关。</p>
<h4 id="_62">使用多元高斯分布进行异常检测</h4>
<ul>
<li>使用下面的公式计算多元高斯分布的参数</li>
</ul>
<p>$$<br />
\mu = \frac{1}{m} \sum_{i=1}^m x^{(i)}<br />
$$</p>
<p>$$<br />
\Sigma = \frac{1}{m} \sum_{i=1}^m (x^{(i)} - \mu) (x^{(i)} - \mu)^T<br />
$$</p>
<ul>
<li>给定一个新的数据 $x$，根据多元高斯分布公式计算其概率密度</li>
</ul>
<p>$$<br />
p(x; \mu, \Sigma) = \frac{1}{(2 \pi)^{n/2} |\Sigma|^{1/2}} exp \left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right)<br />
$$</p>
<ul>
<li>选定一个 $\epsilon$ ，当 $p(x) &lt; \epsilon$ 时就可以判定为异常</li>
</ul>
<p><strong>多元高斯分布与普通高斯分布之间的关系</strong></p>
<p>实际上，普通高斯分布是多元高斯分布的一个特例。当协方差矩阵 $\Sigma$ 是一个对角矩阵时，多元高斯分布就退化为普通高斯分布了。这里不从数学上证明，但可以选择两个特征 $x_1, x_2$ ，通过调整高斯分布的参数，在 3D 图上画出普通高斯分布图和多元高斯分布图。以便直观地查看他们之间的等价关系。</p>
<p><strong>什么时候使用普通高斯分布，什么时候使用多元高斯分布呢？</strong></p>
<p>一般情况下，普通高斯分布更常用。下面是两个算法的特点。</p>
<p>普通高斯分布的特点：</p>
<ul>
<li>计算速度比多元高斯分布要快很多</li>
<li>当训练样例数目 m 比较小时，依然适用</li>
<li>通过<strong>手动添加特征</strong>来对特征相关性进行建模，以解决特征相关性问题。比如本节中的例子，可以增加一个新特征 $x_3=\frac{x_1}{x_2}$ 来手动对相关性进行建模。这样普通高斯分布也可以很好地工作</li>
</ul>
<p>多元高斯分布的特点：</p>
<ul>
<li>自动进行特征相关性关联，而不要人为地去挖掘相关性</li>
<li>计算量要比普通高斯算法大很多，特别是特征数 n 比较大时。因为要对协方差矩阵求逆，即 $\Sigma^{-1}$</li>
<li>只适用于 m &gt; n 的情况下，否则协方差矩阵 $Sigma$ 将是奇异矩阵，不可逆。一般工程实践上，只有在 $m &gt; 10n$ 时才会考虑使用多元高斯分布。</li>
</ul>
<p>另外，在调试多元高斯分布算法时，如果发现协方差矩阵 $\Sigma$ 不可逆，一般有两个可能的原因，一是 m &lt; n；另外一个是特征中的数据有冗余，比如 $x_4 = x_2$，或者 $x_5 = x_3 + x_2$。</p>
<h3 id="_63">推荐系统</h3>
<h4 id="_64">推荐系统的描述</h4>
<p>我们以电影推荐系统来看一下怎么样以机器学习的角度来描述推荐系统。我们记 $n_u$ 为用户的数量，$n_m$ 为电影的数量，$r(i,j) = 1$ 表示用户 j 对电影 i 进行过了评价，$y^{(i,j)}$ 就是它的分数。$r(i,j) = 0$ 表示用户还没观看过这个电影，也没评分过。我们假设用户看过电影后，一定会给电影一个评分，如果没有给，默认评分为零。这样，我们的电影推荐系统的任务，就是根据用户的评分，预测出那些用户还未观看的电影的评分，从而把那些用户可能会给出较高评分的电影推荐给用户。</p>
<h4 id="_65">基于内容的推荐算法</h4>
<p>我们依然以电影推荐系统为例，我们假设 $\theta^{(j)}$ 表示用户 j 的参数，$x^{(i)}$ 为电影 i 的特征向量 (比如爱情电影，动作电影，好吧，如你所愿，可能还有爱情动作片)。这样，用户 j 对电影 i 的预测评分为 $(\theta^{(j)})^T (x^{(i)})$。</p>
<p>接下来的目标，是怎么样获得用户 j 的参数 $\theta^{(j)}$？这个实际上是个线性回归问题，即我们利用用户对现有电影的所有的评分学习出其参数 $\theta^{(j)}$。根据线性回归算法的成本公式，我们的目标是求解线性回归算法的成本函数的最小值时，$\theta^{(j)}$ 的值。假设 $m^{(j)}$ 是用户 j 评价过的电影的总数。n 为电影的特征数。</p>
<p>$$<br />
J(\theta^{(j)}) = \frac{1}{2m^{(j)}} \left[ \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T (x^{(i)}) - y^{(i,j)} \right)^2 + \lambda \sum_{k=1}^n (\theta_k^{(j)})^2 \right]<br />
$$</p>
<p>这里的 $\theta^{(j)} \in R^{n+1}$。累回器部分是指用户所有己评分的电影进行累加。</p>
<p>求解 $\theta^{(j)}$ 的过程就是最小化成本函数的过程。在数学上，我们可以稍微改造一下，得到基于内容的推荐算法的目标函数</p>
<p><strong>求解用户 j 的参数 $\theta^{(j)}$</strong></p>
<p>$$<br />
\frac{1}{2} \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T (x^{(i)}) - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{k=1}^n (\theta_k^{(j)})^2<br />
$$</p>
<p><strong>求解所有用户的参数 $\theta^{(1)}, \theta^{(2)}, &hellip; , \theta^{(n_u)}$</strong></p>
<p>$$<br />
\frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T (x^{(i)}) - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n (\theta_k^{(j)})^2<br />
$$</p>
<p>其参数迭代公式，针对 $k=0$，我们不取正则项：</p>
<p>$$<br />
\theta_k^{(j)} = \theta_k^{(j)} - \alpha \left( \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T - y^{(i)} \right) x_k^{(i)} \right)<br />
$$</p>
<p>针对 $k \ne 0$，包含正则项的迭代公式：</p>
<p>$$<br />
\theta_k^{(j)} = \theta_k^{(j)} - \alpha \left( \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i)} \right) x_k^{(i)} + \lambda \theta_k^{(j)} \right)<br />
$$</p>
<p>其中 $\alpha$ 是学习率。</p>
<h4 id="collaborative-filtering">协同过滤算法 Collaborative Filtering</h4>
<p>基于内容的推荐算法需要对推荐对象提取特征，构成特征向量。我们还是拿电影推荐系统为例，需要对电影进行特征提取，如爱情片，动作片，然后对所有的电影进行特征采集，即针对每个电影写出其爱情成分是多少分，动作成分是多少分。这在工程上工作量非常大。</p>
<p>换一个方法，我们可以在用户注册的时候，让用户告诉我们他的偏好，比如用户喜欢哪些类型的电影。即我们通过调查问卷，事先知道了用户 j 的参数 $\theta^{(j)}$。再根据用户的对看过的电影的评分数据，去推断出电影属于哪种类型，即电影的特征向量 $x^{(i)}$。针对用户 j 没有看过的电影 i ，根据 $(\theta^{(j)})^T (x^{(i)})$ 预测出用户可能的评分，根据预测出来的评分高低，去决定是否向用户推荐这部电影。</p>
<p>怎么样从数学上描述这个过程呢？</p>
<p><strong>计算电影 i 的特征向量 $x^{(i)}$</strong></p>
<p>选取合适的 $x^{(i)}$ ，以便让下面的公式值最小。这是求解电影 i 的特征向量 $x^{(i)}$ 的过程。</p>
<p>$$<br />
\frac{1}{2} \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T (x^{(i)}) - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{k=1}^n (x_k^{(i)})^2<br />
$$</p>
<p><strong>求解所有电影的特征 $x^{(1)}, x^{(2)}, &hellip; , x^{(n_m)}$</strong></p>
<p>选取合适的 $x^{(1)}, x^{(2)}, &hellip; , x^{(n_m)}$ ，以便让下面的公式值最小。</p>
<p>$$<br />
\frac{1}{2} \sum_{i=1}^{n_m} \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T (x^{(i)}) - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2<br />
$$</p>
<p><strong>协同过滤算法</strong></p>
<p>实际工程应用上，事先知道用户 j 的参数 $\theta^{(j)}$ 也是件很难的事。我们从之前的内容知道，有了所有的用户参数 $\theta^{(j)}$，我们就可以估算出电影的特征向量 $x^{(i)}$。或者如果有了电影的特征向量 $x^{(i)}$，我们可以算出用户的偏好参数 $\theta^{(j)}$。这看起来象是个鸡生蛋和蛋生鸡的问题。</p>
<p>实际上，协同过滤算法就是为了解决这个问题的。</p>
<ol>
<li>先随机估算出用户参数 $\theta^{(j)}$</li>
<li>利用己知的 $\theta^{(j)}$ 估算出特征向量 $x^{(i)}$</li>
<li>利用估算出来的特征向量 $x^{(i)}$，反向估算出用户偏好参数 $\theta^{(j)}$</li>
<li>重复步骤 2 ，直到用户参数 $\theta^{(j)}$ 和特征向量 $x^{(i)}$ 收敛到一个合适的值</li>
</ol>
<p>这就是协同过滤算法的核心步骤。协同过滤的一个形象的效应是，当用户对某个电影进行评分时，会帮助算法学习电影的特征，这有利于系统向所有用户推荐合适的电影，同时也让算法更好地学习到用户的偏好。这样所有用户不停地使用系统的过程中，无形中在协同过滤，帮助系统学习出更好的参数，从而更准确地推荐出用户喜欢的电影。</p>
<h4 id="_66">协同过滤算法的实现</h4>
<p>上一节描述的协同过滤算法需要不停地计算 $\theta^{(j)}$ 和 $x^{(i)}$，这样算法的效率实际上是比较低的。从数学角度，一个更高效的算法是把计算 $\theta^{(j)}$ 和 $x^{(i)}$ 的两个成本函数合并起来，得到以 $\theta^{(j)}$ 和 $x^{(i)}$ 为参数的总成本函数，最小化这个成本函数，就可以同时求出 $\theta^{(j)}$ 和 $x^{(i)}$ 的值。</p>
<p>总成本函数为：</p>
<p>$$<br />
J = \frac{1}{2} \sum_{(i,j):r(i,j)=1} \left( (\theta^{(j)})^T (x^{(i)}) - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2 + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n (\theta_k^{(j)})^2<br />
$$</p>
<p>累加器 $\sum_{(i,j):r(i,j)=1}$ 表示针对每个用户评价过的所有的电影进行累加。后两项分别是 $\theta^{(j)}$ 的正则项和 $x^{(i)}$ 的正则项。需要注意的是，总成本函数里 $\theta^{(j)}$ 和 $x^{(i)}$ 都是 n 维向量，即不包含偏置向量 $x_0$。</p>
<p>这样我们可以更新协同过滤算法的实现步骤：</p>
<ul>
<li>用较小的随机数来初始化 $x^{(1)}, x^{(2)}m, &hellip; ,x^{(n_m)}, \theta^{(1)}, \theta^{(2)}, &hellip; , \theta^{(n_u)}$。为什么要用较小的随机数来初始化，而不全用零呢？这是因为我们需要让这些变量具有不同的初始值，以便不会让两个变量变成同一个特征。</li>
<li>最小化成本函数 $J(x^{(1)}, x^{(2)}m, &hellip; ,x^{(n_m)}, \theta^{(1)}, \theta^{(2)}, &hellip; , \theta^{(n_u)})$ ，可以使用梯度下降或其他的优化过的高级算法。其参数迭代公式为</li>
</ul>
<p>$$<br />
\theta_k^{(j)} = \theta_k^{(j)} - \alpha \left( \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T  x^{(i)} - y^{(i)} \right) x_k^{(i)} + \lambda \theta_k^{(j)} \right)<br />
$$</p>
<p>$$<br />
x_k^{(i)} = x_k^{(i)} - \alpha \left( \sum_{i:r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i)} \right) \theta_k^{(i)} + \lambda x_k^{(j)} \right)<br />
$$</p>
<ul>
<li>学习出参数后，针对一个用户 j 的参数为 $\theta^{(j)}$ ，针对这个用户没有看过的电影，学习到的特征为 $x^{(i)}$，那么可以预测到这个用户对这个电影的评分将是 $(\theta^{(j)})^T x^{(i)}$。</li>
</ul>
<p>需要特别注意的是，此处我们没有加偏置变量 $x_0$，也不存在 $\theta_0$。</p>
<h4 id="_67">协同过滤算法的向量化实现</h4>
<p><strong>低秩矩阵分解 Low Rank Matrix Factorization</strong></p>
<p>使用协同过滤算法算出所有用户的参数 $\theta^{(j)}$ 和所有电影的特征 $x^{(i)}$ 之后，我们可以针对某个用户 j 对电影 i 的评分做出预测，预测公式为 $(\theta^{(j)})^T x^{(i)}$ 。如果我们想要一次性计算所有用户对所有电影的评分，我们可以写成下面的矩阵：</p>
<p>$$<br />
\begin{bmatrix}<br />
(\theta^{(1)})^T x^{(1)} &amp; (\theta^{(2)})^T x^{(1)} &amp; \cdots &amp; (\theta^{(n_u)})^T x^{(1)} \\<br />
(\theta^{(1)})^T x^{(2)} &amp; (\theta^{(2)})^T x^{(2)} &amp; \cdots &amp; (\theta^{(n_u)})^T x^{(2)} \\<br />
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\<br />
(\theta^{(1)})^T x^{(n_m)} &amp; (\theta^{(2)})^T x^{(n_m)} &amp; \cdots &amp; (\theta^{(n_u)})^T x^{(n_m)} \\<br />
\end{bmatrix}<br />
$$</p>
<p>这是个 $n_m \times n_u$ 的矩阵。我们把所有的电影特征 $x^{(i)}$ 写成一个 $n_m \times n$ 的矩阵，其中 n 是电影的特征个数。</p>
<p>$$<br />
X = \begin{bmatrix}<br />
- &amp; (x^{(1)})^T &amp; - \\<br />
- &amp; (x^{(2)})^T &amp; - \\<br />
- &amp; \vdots &amp; - \\<br />
- &amp; (x^{(n_m)})^T &amp; - \\<br />
\end{bmatrix}<br />
$$</p>
<p>再把所有的用户参数 $\theta^{(j)}$ 写成一个 $n_u \times n$ 的矩阵：</p>
<p>$$<br />
\Theta = \begin{bmatrix}<br />
- &amp; (\theta^{(1)})^T &amp; - \\<br />
- &amp; (\theta^{(2)})^T &amp; - \\<br />
- &amp; \vdots &amp; - \\<br />
- &amp; (\theta^{(n_u)})^T &amp; - \\<br />
\end{bmatrix}<br />
$$</p>
<p>那么 $Y = X \Theta^T$ 就可以一次性算出所有用户对所有电影的评分。其中 $X \in R^{n_m \times n}, \Theta^T \in R^{n \times n_u}$，其内积 $Y \in R^{n_m \times n_u}$。</p>
<p><strong>推荐相似的电影</strong></p>
<p>我们还是以电影为例，假设我们已经通过协同过滤算法学习到了所有的电影特征 $x^{(i)}$。假设这个时候用户在浏览电影 i ，我们要推荐 5 部相似的电影给用户。怎么样找到这 5 部相似的电影呢？</p>
<p>我们可以遍历所有的电影，通过公式 $\| x^{(i)} - x^{(k)} \|$ 找出和正在浏览的电影“距离最小”，即相似度最高的 5 部电影。</p>
<h4 id="mean-normalization">均值归一化 Mean Normalization</h4>
<p>假设现在有个新用户 j 没有对任何电影进行打分。那么根据协同过滤算法的成本函数：</p>
<p>$$<br />
J = \frac{1}{2} \sum_{(i,j):r(i,j)=1} \left( (\theta^{(j)})^T (x^{(i)}) - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2 + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n (\theta_k^{(j)})^2<br />
$$</p>
<p>第一部分将为 0 ，因为对用户 j ，没有 $r(i,j)=1$ 的项。第二部分将为一个固定值，因为已经学习好了电影的特征，所以 $x_k^{(i)}$ 将是常量，所以针对新用户 j 问题将简化为最小化 $\frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n (\theta_k^{(j)})^2$ ，这个计算结果将使 $\theta^{(j)}$ 为全 0 。</p>
<p>这样的话，这个用户对所有电影的评分将预测为 0 ，我们也就没有什么他喜欢的电影推荐给他了。</p>
<p>怎么样解决这个问题呢？</p>
<p>简单地讲，如果一个新用户没有评分过任何电影，我们可以预测这个用户对新电影的评分为这个电影的评分的平均值。用数学的语言来描述就是，我们需要先对电影评分数据进行<strong>均值归一</strong>处理。</p>
<p>假设我们有所有的电影评分矩阵 $Y \in R^{n_m \times n_u}$，对其按行求平均值，得到 $\mu \in R^{n_m}$。然后我们计算 $Y - \mu$ 作为我们协同过滤算法的训练数据集。这样训练出来 $\theta^{(j)}$ 和 $x^{(i)}$ 之后，针对新用户 j 对电影 i 的预测评分公式将变成 $(\theta^{(j)})^T x^{(i)} + \mu_i$。</p>
<p>还有一种情况是如果有一部新的电影，所有人都没有评分过，那么这个电影的特征值将全为 0 。我们也可以用均值归一法来处理，但这样处理是否合理需要从业务层面去理解。比如一部新电影，所有人都没看过，也没评分过，我们就不应该推荐给任何人。从业务层面，一个新电影可能会有专门的展示区域，比如“新片速递”。</p>
<h2 id="week-10">Week 10 大规模机器学习</h2>
<h3 id="_68">大规模数据的梯度下降算法</h3>
<h4 id="_69">大规模数据的算法学习</h4>
<p>根据梯度下降算法的迭代公式</p>
<p>$$<br />
\theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=0}^m \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)<br />
$$</p>
<p>假设我们有 100,000,000 条数据，那么每进行一次参数迭代，就需要进行一亿次的计算，这样的计算量太大了，会导致需要巨量的计算来训练一个算法。</p>
<p>一个解决方案是随机选取 1000 条数据来训练算法，然后画出算法的学习曲线图 (Learning Curve)。从学习曲线图上来观察，增加训练样例个数的增长对算法是否有帮助。以此来决定是通过增加训练样例的个数来改进算法还是通过其他的途径来改进算法。</p>
<h4 id="stochastic-gradient-descent">随机梯度下降算法 Stochastic gradient descent</h4>
<p>另外一个解决大规模数据的算法学习的方法是采用<strong>随机梯度下降算法</strong>。</p>
<ul>
<li>对训练样例进行随机排序</li>
<li>从 1 到 m 遍历随机排序后的训练样例，针对单个样例 i，对每个参数 j 进行迭代</li>
</ul>
<p>$$<br />
\theta_j = \theta_j - \alpha \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)<br />
$$</p>
<ul>
<li>根据训练样例的大小，决定步骤 2 是执行一次还是多次。一般情况下是执行 1 - 10 次。</li>
</ul>
<p>随机梯度下降算法和梯度下降算法相比，有明显的特点：</p>
<ul>
<li>每次参数迭代时，只针对一个训练样本数据进行计算，大大节省了计算工作量</li>
<li>梯度下降算法每次迭代时，都会得到一个更优的，离目标值更近的参数。但随机梯度下降算法就不一定，它在某个梯度下降的过程中可能反而离目标值更远了。但总体上，随机梯度下降也会不断地靠近目标值。最后也会不停地在目标值附近徘徊。</li>
<li>梯度下降算法一般只做一次。而随机梯度下降算法可能根据数据量的大小会执行 1 - 10 次。</li>
</ul>
<h4 id="_70">小批量梯度下降</h4>
<p>梯度下降算法在每次参数迭代时，都需要遍历所有的训练样例。而随机梯度下降算法每次只取一个样例来更新参数。小批量梯度下降算法介于两者之间，每次参数迭代时，取 b 个样例进行计算。b 的取值一般是 10 ，或者介于 2 - 100 之间的一个数值。</p>
<ul>
<li>$k = 1$ 开始使用梯度下降来更新参数</li>
</ul>
<p>$$<br />
\theta_j = \theta_j - \alpha \frac{1}{b} \sum_{i=k}^{b+k} \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)<br />
$$</p>
<ul>
<li>$k = k + b$，跳到步骤 1 继续执行，直到 $k + b &gt; m$ 为止</li>
<li>跳到步骤 1 继续执行数次循环，循环次数由算法收敛的最终结果决定</li>
</ul>
<p>小批量梯度下降算法的性能肯定会比梯度下降算法快，如果使用<strong>向量化</strong>来实现参数更新，一次性并行计算出 b 个样例的微分项，那么其算法性能也会比随机梯度下降算法还要快。</p>
<h4 id="_71">检查随机梯度下降算法是否收敛</h4>
<p>针对梯度下降算法，检查其是否收敛的方法是针对训练样例算出其成本 $J_{train}$ 。然后每次计算时都需要遍历所有的训练样例，计算成本很高。针对随机梯度下降算法，我们可以使用一种计算成本较低的方式：</p>
<ul>
<li>定义 $cost(\theta, (x^{(i)}, y^{(i)})) = \frac{1}{2} \left(h(x^{(i)}) - y^{(i)}\right)^2$</li>
<li>在更新参数的过程中，在<strong>更新参数之前</strong>计算当前的训练样例 $(x^{(i)}, y^{(i)})$ 的成本</li>
<li>每隔 1000 次迭代，计算出过往 1000 次样本的 cost 的平均值，然后画出迭代次数和过往 1000 次迭代 cost 的平均值的图形，从图形里我们基本可以看到算法是否在收敛</li>
</ul>
<p><strong>成本收敛图</strong></p>
<p>随机梯度下降算法的成本收敛图有几个特点：</p>
<ul>
<li>它不是平滑的，而是不停地波动的。这是因为单个样例去更新参数时，可能会让参数往更坏的方向发展</li>
<li>如果成本收敛图波动地太剧烈了，可以试着增加平均迭代的次数，比如原来是 1000，增加到 5000 可以让成本收敛图更平滑</li>
<li>如果我们发现成本在发散，那么可能是学习率太大了，需要减小学习率</li>
<li>如果我们发现成本收敛图基本上在一个直线上振荡，那么可能是我们的特征没有选择对或其他的原因，需要检查算法模型</li>
</ul>
<p><strong>学习率</strong></p>
<p>在随机梯度下降算法中，最终算法不会收敛在全局最小值处，而是在全局最小值处不停地振荡。这对大部分问题是可以接受的，但如果需要让随机梯度下降算法振荡幅度更小，以便更接近全局最小值处，我们可以通过不断地减少学习率 $\alpha$ 来实现。</p>
<p>$$<br />
\alpha = \frac{const1}{IterNums + const2}<br />
$$</p>
<p>这里 const1 和 const2 是两个额外的参数，用来调整 $\alpha$ 的值。IterNums 表示算法迭代的次数，随着迭代次数的增加，逐步减小学习率。在实际应用中，可能有些人不愿意使用这个方法，因为这个方法引入了额外的两个参数 const1 和 const2 ，我们需要花时间去调试这两个额外参数以确保算法的性能可靠。</p>
<h3 id="_72">高级话题</h3>
<h4 id="_73">在线学习</h4>
<p>今天，很多网站都有大量的用户参与其中，持续不断地使用网站会持续不断地产生数据。在线学习的目的，就是通过对用户持续不断产生的数据的学习，来给网站运营者提供决策依据。</p>
<p><strong>快递价格策略</strong></p>
<p>假设你运营着一个购物网站，网站同时提供可选的有偿快递服务，如果用户选择了快递服务标识为 $y=1$，如果用户不选择快递服务标识为 $y=0$。假设用户的特征由向量 $x$ 表示，这个特征里包含了快递的价格，目的地等信息，我们想要通过机器学习来得出一组参数 $\theta$，以便确定对一个给定的新用户 $x$，对于给定的价格，它使用我们的快递服务的概率 $p(y=1|x;\theta)$ 是多少。这样有利于帮助我们制定出合适的快递价格策略。那么怎么样来学习出参数 $\theta$ 呢？</p>
<ul>
<li>当一个用户完成一笔交易后，我们得到了用户的数据 $(x, y)$</li>
<li>使用这个最新的用户数据来更新我们的参数 $\theta$</li>
</ul>
<p>$$<br />
\theta_j = \theta_j - \alpha \left((h_\theta(x) - y) x_j\right)<br />
$$</p>
<ul>
<li>跳回步骤一。持续不断地根据新用户的数据来更新我们的参数</li>
</ul>
<p>学习出参数 $\theta$ 后，我们就可以根据这个参数来调整我们的价格，以便调整用户使用我们的快递服务的概率。同时也可以观察到，随着时间的变化，用户对价格的敏感度也会发生变化，而我们的算法可以自适应，智能地计算出合理的价格。</p>
<p>算法里，取出用户数据，学习后直接把数据丢弃。这是因为我们的网站有持续不断的数据流供我们学习，理论上数据是无限的，所以不需要把数据保存起来。当然，如果数据量比较小，也可以采集数据后，保存在数据库里供集中学习，反复使用。</p>
<p><strong>智能搜索</strong></p>
<p>假设我们经营着一家卖手机的在线商店。商店网站提供手机产品搜索功能。假设一个用户搜索 &ldquo;Android phone 1080p camera&rdquo;，我们需要从我们的产品库里返回最符合用户预期的手机产品。怎么样实现这个算法呢？</p>
<p>假设，我们提练出手机的特征 $x$，这些特征包括用户搜索的关键词里有几个和手机的名称相符，有几个和手机的参数相符，有几个和手机的描述信息相符。最终根据现有的 $x$ 和参数 $\theta$ 的值算出用户会点击这个产品的概率预测值 $p(y=1|x;\theta)$ ，根据预测值的大小展示给用户前 10 个产品。</p>
<p>当用户在浏览搜索结果时，$y=1$ 表示用户点击了搜索结果中的某个手机。$y=0$ 表示用户没有点击这个搜索出来的手机产品。这样，这个用户的搜索行为就给我们提供了优化我们的搜索策略的源材料。简单地讲，我们可以拿用户的这个搜索行为和其点击行为，来更新我们的参数 $\theta$。这样下次另外一个用户来搜索一个产品时，我们就可以用根据这个用户的点击行为优化过的参数 $\theta$ 来计算新用户的点击率 CTR (Click Through Rate)。然后根据点击率的可能性大小，返回前 10 个最大点击率的产品给用户。</p>
<p>这样当持续不断地有用使用我们的搜索功能时，我们的网站就可以持续不断地学习，并优化搜索结果。使搜索出来的结果越来越满足用户的预期。这就是智能搜索的精髓所在。</p>
<p>从这些示例可以看到，在线学习和随机梯度下降算法很类似，唯一的区别是，在线学习不是从固定的训练数据集里对算法进行训练，而是持续不断地从数据流里来学习训练算法。</p>
<h4 id="map-reduce-and-data-parallelism">映射化简和数据并行处理 Map Reduce and Data Parallelism</h4>
<p>对一些机器学习问题，其数据量可能大得惊人，大到无论采用哪种算法，都不可能在一台计算机上进行处理。这个时候我们就需要使用 Map Reduce 方法来进行机器学习训练。</p>
<p><strong>Map Reduce</strong></p>
<p>假设，我们在使用批量的梯度下降算法来对一个大规模的训练数据集进行学习。根据其参数迭代公式：</p>
<p>$$<br />
\theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m} \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)<br />
$$</p>
<p>在一次迭代过程中，由于数据集极大，我们不可能在一台计算机上对所有训练样例求和 $\sum_{i=1}^{m} \left(\left(h(x^{(i)}) - y^{(i)}\right) x_j^{(i)}\right)$。Map Reduce 的核心思想是把 m 份数据分成 k 等份，每份训练样例数据集的个数是 $b=m/k$。然后把这 k 份数据分给 k 台计算机并行处理。每台计算机只需要求 m/k 份数据的和。计算完成后，把结果送到一个中央处理计算机上。中央处理计算机汇总所有的计算机的计算结果后，完成一个参数迭代的过程。这样，我们就能把运算效率提高接近 k 倍。</p>
<p><strong>Map Reduce 算法适用的场景</strong></p>
<p>关键点是一个机器学习算法在学习的过程中，<strong>是否要计算所有训练样例的和</strong>。实际上，大部分机器学习算法在学习的过程中，确实都在计算所有训练样例的和。如果是这种情况，那么它就适用于 Map Reduce 算法，从而使用多台计算机来并行处理数据，提高机器学习的效率。这样算法就可以处理超大型的数据集了。</p>
<p>一个例子是逻辑回归算法，其成本函数和成本函数的微分项公式如下：</p>
<p>$$<br />
J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)})) \right]<br />
$$</p>
<p>$$<br />
\frac\partial{\partial{\theta_j}}J(\theta) = \frac{1}{m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)}<br />
$$</p>
<p>这样，我们可以把两个求和 $\sum_{i=1}^m y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\theta(x^{(i)}))$ 和 $\sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)}$ 分别放在 k 台计算机上执行，一台计算机执行一部分求和，并把求和结果发送给中央处理计算机，中央处理计算机收到所有结果后，再求和，然后把结果返回给一些类似 <code>fminunc</code> 之类的算法，即可使用 Map Reduce 处理大规模数据。</p>
<p><strong>多核 CPU</strong></p>
<p>现代计算机的 CPU 一般都是多核的。利用多核 CPU 进行并行计算，也可以使用 Map Reduce 的方法。简单地讲，就是把计算过程分到 CPU 的多个核心上并行计算，然后再汇总起来。使用多核计算有个优点是不需要担心网络延迟问题。</p>
<p>在使用向量化计算时，有些线性代数函数库本身支持多核 CPU 并行处理，针对这种函数库，我们就不需要使用 Map Reduce 来实现并行计算，而只需要按照常规的方法向量化实现即可，库本身会把计算量分配给不同的 CPU 核心，完成多核并行计算。</p>
<p>目前有一些优秀的开源系统使用了 Map Reduce 运算机制的框架，如 Hadoop 和 Spark。实际应用时，可以使用这些优秀的开源框架来实现分布式计算。</p>
<h2 id="week-11-ocr">Week 11 图像 OCR</h2>
<h3 id="_74">问题描述和机器学习流水线</h3>
<p>OCR 的全称是 Optional Character Recgnize。目的是识别图像中的文字。它基本上分成下面几个步骤：</p>
<ul>
<li>文字区域检测：扫描图像，从图像中找出文字区域</li>
<li>字符分隔：把文字区域里的文字逐个字符分隔</li>
<li>字符识别：通过分类算法，逐个识别出字符</li>
<li>拼写检查：对识别出的字符组成的单词进行拼写检查，以便纠正可能的识别错误</li>
</ul>
<p>机器学习流水线的作用，就是把复杂问题进行分隔，各个模块形成一个流水线。比如上述的 OCR 问题，扣除拼写检查，可以分隔成三个独立的组件，每个组件可能都有自己的机器学习算法。上一个组件处理完的输出作为下一个组件的输入。这样就组成了一个流水线。</p>
<h3 id="_75">滑动窗口</h3>
<p>我们可以使用滑动窗口算法来对文字区域进行检测。先来看一个更简单的例子，怎么样用滑动窗口算法对一幅图像中的行人进行识别。</p>
<ul>
<li>数据采集：选取一个合适的图像大小，比如 80 x 40 分辨率。采集 1,000 个包含行人的图像和 1,000 个不包含行人的图像。以这些数据来作为我们的训练样例。</li>
<li>算法学习：运用神经网络算法或其他的分类算法，对训练样例进行学习，学习出的一组参数可以对一个输入为 80 x 40 的图像进行预测，判断图像里是否包含行人。</li>
<li>选定一个小的矩形，比如 40 x 20，从待识别图像的左上角开始，取出一个小矩形，放大到 80 x 40 ，然后作为输入，通过我们学习出来的分类器参数，判断选取出来的图像是否包含行人。</li>
<li>接着，在待识别图像上向右移动一小步，移动 1 个像素点通常能得到最好的结果，但运算量太大，一般选择 4 个像素点或 8 个像素点，甚至更多。把取出的新的矩形放大到 80 x 40，然后像上一步骤一样，检测图像里是否有行人。</li>
<li>持续右移图像，逐个图像识别。直到达到待识别图像的最右侧时。把滑动窗口移回最左边，然后向下移动一小步，取出新的图像进行识别。通过这样的步骤，走到扫描完整个待识别图像为止。</li>
<li>接着，选取更大的矩形，比如 44 x 22，然后放大到 80 x 40。重复上述步骤。</li>
<li>持续选取更大的矩形，缩放到目标尺寸 80 x 40，然后进行识别。直到遍历完所有可能的矩形为止。</li>
</ul>
<p><strong>文字区域检测</strong></p>
<p>这就是滑动窗口算法识别行人的流程。文字区域识别分稍微复杂一点。</p>
<ul>
<li>数据采集：选取一个合适的图像大小，比如 20 x 20 分辨率。采集 1,000 个包含文字的图像和 1,000 个不包含文字的图像。以这些数据来作为我们的训练样例。</li>
<li>算法学习：运用神经网络算法或其他的分类算法，对训练样例进行学习，学习出的一组参数可以对一个输入为 20 x 20 的图像进行预测，判断图像里是否包含文字。</li>
<li>滑动窗口扫描：使用上文描述的滑动窗口的方法，搜索整个图像，识别出所有的字母区域。并把所有的字母区域标识为白色，不包含字母的标识为黑色。</li>
<li>展开器：把包含文字标识为白色的图像输入给展开器，展开器会对每个白色的区域进行扩展，比如把白色区域的周围 10 个像素都标识为白色。这样那些可能的文字就会连成一片，形成一个矩形。这些矩形就是我们使用滑动窗口算法检测出来的文字区域。</li>
</ul>
<p><strong>字符分隔</strong></p>
<p>针对字符分隔，我们依然使用滑动窗口算法来实现。</p>
<ul>
<li>数据采集：选取合适的图像大小，比如 20 x 20，采集一组图像数据，如果这个图像包含了两个字符的分界线，即图像中左边包含一半的字符，右边包含另外一半的字符，那么这个图像标识为 $y=1$。如果图像不包含字符分隔线，标识为 $y=0$。</li>
<li>算法学习：使用神经网络或者其他的分类器算法，训练出一组参数。对于给定的一个图像，我们能判断出这个图像里是否包含字符分界线。</li>
<li>滑动窗口：假设我们要识别的文字是单行文字。可以使用一维滑动窗口算法，扫描文字区域，从左到右逐渐移动，选取图像来判断是否包含字符分界线。如果包含，那么在图像中间画一条线，即把两个字符分隔了。如果不包含字符分界线，则继续向右移动。这样完成扫描后，我们就可以把文字区域里的逐个字符进行分隔。</li>
</ul>
<p><strong>字符识别</strong></p>
<p>字符识别就相对比较简单了。可以通过监督学习算法，比如神经网络对单个字符进行识别。典型地步骤就是采集足够多的字符图像，然后使用机器学习算法训练出一组参数。利用这组参数，对分隔好的字符逐个进行识别。</p>
<h3 id="_76">人工合成数据</h3>
<p>机器学习的关键任务之一是获取足够多的数据。其中一个方法是人工合成数据，有两种途径，一种是根据现有的小容量数据进行一定的变换，从而得到更多的数据；另外一种是白手起家，直接创造数据。</p>
<p>针对我们的字符识别的任务，我们可以从网上下载不同的字库，处理字库里的字符，把它转化为图片。然后给这些字符图片加上一些随机的背景，这样我们就有了大量的训练数据。另外一个方法是，从我们现有的训练样例里，对字符图片进行变形操作，这样就可以从一个训练数据变换出多个训练数据。这两种方法都可以用来合成训练数据。</p>
<p>另外一个例子是语音识别，假设我们要识别一段从语音，我们有这个语音的清晰版本数据。这个时候，我们可以给这个语音加一些背景噪音，来合成出多个训练数据。比如加上电流音，加上背景音乐，加上吵杂的街道声等等。</p>
<p>由此可见，合成数据的关键是<strong>对正常的数据引入一些有意义的干扰</strong>。什么是有意义的干扰？在测试验证数据集里可以看到的干扰，或者说真实环境下可能产生的干扰，就是有意义的干扰。那些随机噪声干扰是没有意义的。</p>
<p>在决定是否获取更多的数据时，一般需要考虑一些事情：</p>
<ul>
<li>在决定获取更多数据之前，需要确保获取更多数据能改进你的算法性能。比如，我们有一个低偏差 (low bias, 过拟合) 的分类器算法，这个时候增加数据就对算法性能有帮助。比如，针对神经网络，我们可以增加隐藏层的个数，从而获得一个低偏差，高方差的分类算法。</li>
<li>要获取 10 倍于现在的训练数据需要花多长时间？不断地问这个问题，和团队讨论这个问题，有时候总会有一些收获。<ul>
<li>人工合成数据</li>
<li>手动收集数据，并给数据打标签。有时候这种最笨的方法会带来很大的惊喜。比如原来我们只有 1,000 个训练数据，要获取 10,000 个训练数据。假设每个数据打标签的时间是 10 秒，一个人一天工作 8 小时，我们只需要花 3.5 天时间就可以获得足够的数据。</li>
<li>众包获取数据。有一些众包网站，可以使用很低的价格人工给数据打标签。但这种渠道需要特别注意数据的质量。</li>
</ul>
</li>
</ul>
<p>总之，在决定获取数据之前，最好把学习曲线画出来，通过学习曲线观察我们需要在哪些方面去做工作来优化算法性能。</p>
<h3 id="ceiling-analysis">上限分析 Ceiling Analysis</h3>
<p>我们还是以图片 OCR 的流水线为例，来看一下上限分析的思想和流程。</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">+---------+      +---------------+      +-----------+     +-----------+
|  图片    |  -&gt; |  文字区域检测    |  -&gt;  |  字符分隔  |  -&gt; |  字符识别  |
+---------+      +---------------+      +-----------+     +-----------+
</pre></div>


<p>当我们的算法性能没有达到预期要求时，我们需要通过上限分析去检查流水线里的哪个节点值得我们花时间去改善。假设我们的上限分析得到下面的数据：</p>
<table>
<thead>
<tr>
<th>节点</th>
<th>识别准确率</th>
</tr>
</thead>
<tbody>
<tr>
<td>整体准确率</td>
<td>72%</td>
</tr>
<tr>
<td>文字区域检测 提高到 100% 准确率后</td>
<td>89%</td>
</tr>
<tr>
<td>字符分隔 也提高到 100% 准确率后</td>
<td>90%</td>
</tr>
<tr>
<td>字符识别 也提高到 100% 准确率后</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>表中，我们手动把各个节点的准确率依次提高到 100% (比如，通过人工识别的方式，把准确率提高到 100%) ，再去观察对整个系统准确率的影响。通过上表们可以看出来，提高文字区域检查的准确率后，系统整体准确率提升了 17% ，而提高字符分隔的准确率后，系统整体准确率只上升了 1%。提高字符识别的准确率后，系统整体准确率提升了 10% 。由这些上限分析，可以看出来，我们应该优先安排资源去优化文字区域检测节点和字符识别节点。而基本不用安排工程师去优化字符分隔节点，因为这个节点已经足够好了，再优化对系统整体性能帮助不大。</p>
<p>我们来看另外一个复杂一点的例子。假设我们有个人脸识别系统，用在智能家居上，当有人出现在摄像头前面时，我们需要拍照，然后检测这个人是不是主人，以便决定是否开门。</p>
<p>我们的机器学习流水线如下</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%">                                                         +---------+
                                            +----------&gt; | 眼部分隔 | -------+
                                            |            +---------+        |
                                            |                               v
+---------+      +-------------+      +-----------+      +---------+      +---------+
| 拍摄照片 |  -&gt;  | 移除照片背景  |  -&gt;  |  脸部识别   |  -&gt; |  鼻子分隔  | -&gt;  | 逻辑回归  | -&gt; 是否是主人
+---------+      +-------------+      +-----------+      +---------+      +---------+
                                            |                               ^
                                            |            +---------+        |
                                            +----------&gt; | 嘴部分隔 | -------+
                                                         +---------+
</pre></div>


<p>解释一下这个流水线：</p>
<ul>
<li>脸部识别：使用滑动窗口的方法，识别出照片中的人脸，并且把人脸用一个长方形截取出来，作为下一个节点的输入</li>
<li>眼部分隔：以人脸作为输入，使用滑动窗口的方法，识别出眼部区域，并用长方形把眼部图片截取出来，作为下一节点的输入</li>
<li>鼻子分隔：用上述相同的方法，截取出人的鼻子图片</li>
<li>嘴部分隔：用上述相同的方法，截取出人的嘴部图片</li>
<li>逻辑回归：以眼部图片，鼻子图片，嘴部图片作为输入特征，通过训练好的逻辑回归算法或神经网络算法的参数，判断输入是否是主人</li>
</ul>
<p>通过上限分析，我们得出下面的上限分析表</p>
<table>
<thead>
<tr>
<th>节点</th>
<th>识别准确率</th>
</tr>
</thead>
<tbody>
<tr>
<td>整体准确率</td>
<td>85%</td>
</tr>
<tr>
<td>移除照片背景</td>
<td>85.1%</td>
</tr>
<tr>
<td>脸部识别</td>
<td>91%</td>
</tr>
<tr>
<td>眼部识别</td>
<td>95%</td>
</tr>
<tr>
<td>鼻子识别</td>
<td>96%</td>
</tr>
<tr>
<td>嘴部识别</td>
<td>97%</td>
</tr>
<tr>
<td>逻辑回归</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>由上限分析可以看出来，我们应该优先花精力去优化脸部识别节点，眼部识别节点和逻辑回归节点。而照片背影移除对识别准确率影响很低，针对这个情况，我们还可以试着去除照片背景节点，看看对算法的准确率是否有影响，以便决定我们的流水线里是否要包含移除照片背景这个节点。</p>
<p>很多经验丰富的机器学习工程师都不敢依赖直觉去判断哪个模块需要改善，而是利用上限分析法客观地去分析哪个模块有改善的空间。Andrew 老师还提过一个他亲自见过的例子，有个团队 (两个人) 花了 18 个月去优化 移除照片背景 的算法，他们也确实研究出了非常优秀的背景移除算法，且还发表了一些论文。但到头来发现对整体算法的性能没有帮助。所以做好客观分析，决定资源投入方向是非常重要的事情。</p>
<h2 id="_77">课程总结</h2>
<ul>
<li>监督学习算法<br />
  这门课花了大量时间介绍监督学习算法，包括线性回归 linear regression ，逻辑回归 logistic regression ，神经网络 neural networks， 向量状态机 SVM。这些算法都是处理带标签的数据，即 $(x^{(i)}, y^{(i)})$。</li>
<li>无监督学习算法<br />
  我们也花了不少时间学习无监督学习算法，包括 K 均值分类算法 K-means ，主成分分析法 PCA 用来对高维数据进行降维，异常检测 anomaly detection 。这些算法处理的是不带标签的数据，即 $x^{(i)}$。当然，异常检测会使用一些带标签的数据来评估算法的性能。</li>
<li>特殊应用<br />
  我们也讨论了特殊应用，包括推荐系统，大规模机器学习系统等话题，包括并行计算，映射化简 map-reduce 方法等。还讨论了用于计算机视觉方面的滑动窗口技术，</li>
<li>构建机器学习系统的建议<br />
  包括分析算法是否有效。比如算法的偏差和方差 (bias/variance)，用来解决高方差的正则化方法。也花了大量时间讨论了下一步有哪些行动可以用来优化算法性能。我们介绍了评价矩阵，包括查准率，召回率，以及 F1 分数。还有数据集的分类方法，包括训练数据集，交叉验证数据集以及测试数据集。我们还介绍了算法诊断的方法，包括学习曲线，误差分析，上限分析。这些工具和方法将帮助我们确定算法的问题点，以便我们做出正确的决策。</li>
</ul>
	<hr/>
	<h6>Post by <a href="../author/joey-huang.html">Joey Huang</a> under <a href="../category/notes.html">notes</a> on 2015-08-29(Saturday) 20:20.</h6>
</article>

<hr/>
<div class="row">
	<div class="small-12 columns">
		<h3>Comments</h3>
		<div id="disqus_thread"></div>
		<script type="text/javascript">
			var disqus_shortname = 'kamidox';
			(function() {
				var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
				dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
				(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
			})();
		</script>
		<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
	</div>
</div>
						</div>
						<!-- End Main Content -->
						<!-- Sidebar -->
						<aside class="medium-3 hide-for-small-only columns">
							<div class="panel">
								<h5>Places</h5>
								<ul class="side-nav">
										<li><a href="http://blog.kamidox.com/feeds/rss.xml" rel="alternate">RSS Feed</a></li>

								</ul>
							</div>


							<div class="panel">
								<h5>Categories</h5>
								<ul class="side-nav">
										<li><a href="../category/android.html">android</a></li>
										<li><a href="../category/essay.html">essay</a></li>
										<li><a href="../category/flask.html">flask</a></li>
										<li><a href="../category/ml.html">ml</a></li>
										<li><a href="../category/python.html">python</a></li>
										<li><a href="../category/tools.html">tools</a></li>
										<li><a href="../category/werkzeug.html">werkzeug</a></li>
								</ul>
							</div>

							<div class="panel">
								<h5>Tags</h5>
								<ul class="tag-cloud">
										<li class="tag-4"><a href="../tag/contacts.html">contacts</a></li>
										<li class="tag-4"><a href="../tag/uml.html">uml</a></li>
										<li class="tag-4"><a href="../tag/socketserver.html">SocketServer</a></li>
										<li class="tag-4"><a href="../tag/contacts-provider.html">contacts provider</a></li>
										<li class="tag-2"><a href="../tag/flask.html">flask</a></li>
										<li class="tag-3"><a href="../tag/pelican.html">pelican</a></li>
										<li class="tag-2"><a href="../tag/android.html">android</a></li>
										<li class="tag-3"><a href="../tag/sublime.html">sublime</a></li>
										<li class="tag-2"><a href="../tag/tools.html">tools</a></li>
										<li class="tag-4"><a href="../tag/github.html">github</a></li>
										<li class="tag-4"><a href="../tag/decorator.html">decorator</a></li>
										<li class="tag-4"><a href="../tag/wekzeug.html">wekzeug</a></li>
										<li class="tag-1"><a href="../tag/python.html">python</a></li>
										<li class="tag-4"><a href="../tag/patchrom.html">patchrom</a></li>
										<li class="tag-3"><a href="../tag/markdown.html">markdown</a></li>
										<li class="tag-1"><a href="../tag/thought.html">thought</a></li>
										<li class="tag-4"><a href="../tag/miui.html">miui</a></li>
										<li class="tag-1"><a href="../tag/machine-learning.html">machine-learning</a></li>
								</ul>
							</div>

							<div class="panel">
								<h5>Monthly Archives</h5>
								<ul class="side-nav">
											<li><a href="/posts/2016/01/index.html">January 2016 (1)</a></li>
											<li><a href="/posts/2015/12/index.html">December 2015 (10)</a></li>
											<li><a href="/posts/2015/11/index.html">November 2015 (6)</a></li>
											<li><a href="/posts/2015/10/index.html">October 2015 (2)</a></li>
											<li><a href="/posts/2015/09/index.html">September 2015 (7)</a></li>
											<li><a href="/posts/2015/08/index.html">August 2015 (1)</a></li>
											<li><a href="/posts/2015/07/index.html">July 2015 (1)</a></li>
											<li><a href="/posts/2015/05/index.html">May 2015 (1)</a></li>
											<li><a href="/posts/2015/04/index.html">April 2015 (1)</a></li>
											<li><a href="/posts/2015/03/index.html">March 2015 (3)</a></li>
											<li><a href="/posts/2015/02/index.html">February 2015 (2)</a></li>
											<li><a href="/posts/2015/01/index.html">January 2015 (2)</a></li>
											<li><a href="/posts/2014/12/index.html">December 2014 (3)</a></li>
											<li><a href="/posts/2014/11/index.html">November 2014 (4)</a></li>
											<li><a href="/posts/2014/10/index.html">October 2014 (6)</a></li>
											<li><a href="/posts/2014/09/index.html">September 2014 (1)</a></li>
											<li><a href="/posts/2014/07/index.html">July 2014 (1)</a></li>
								</ul>
							</div>

						</aside>
						<!-- End Sidebar -->
					</div>

					<!-- Footer -->
					<footer class="row">
						<div class="medium-9 small-12">
							<hr/>
							<p class="text-center">Powered by <a href="http://getpelican.com">Pelican</a> and <a href="http://foundation.zurb.com/">Zurb Foundation</a>. Theme by <a href="http://hamaluik.com">Kenton Hamaluik</a>.
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1253471695'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1253471695%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
							</p>
						</div>
					</footer>
					<!-- End Footer -->
				</section>
				<a class="exit-off-canvas"></a>
			</div><!--off-canvas inner-->
		</div><!--off-canvas wrap-->

		<script src="../theme/js/jquery.js"></script>
		<script src="../theme/js/foundation.min.js"></script>
		<script>
			$(document).foundation();
		</script>
	</body>
</html>